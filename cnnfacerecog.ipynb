{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Facial Recognition**"
      ],
      "metadata": {
        "id": "CfP9wxzaPCYJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "24DiHilIOhoJ"
      },
      "outputs": [],
      "source": [
        "!pip install -q torch torch-vision keras"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare the Dataset"
      ],
      "metadata": {
        "id": "4z30UnxePMud"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/images.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "weDSNgFqPLHX",
        "outputId": "497c3158-1e39-4e2f-deb9-f94e32041671"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/images.zip\n",
            "   creating: outputimages/ankan/\n",
            "  inflating: outputimages/ankan/1_0_1641.jpg  \n",
            "  inflating: outputimages/ankan/1_0_5373.jpg  \n",
            "  inflating: outputimages/ankan/1_0_7667.jpg  \n",
            "  inflating: outputimages/ankan/1_0_9120.jpg  \n",
            "  inflating: outputimages/ankan/1_0_9649.jpg  \n",
            "  inflating: outputimages/ankan/2_0_1309.jpg  \n",
            "  inflating: outputimages/ankan/2_0_2196.jpg  \n",
            "  inflating: outputimages/ankan/2_0_3780.jpg  \n",
            "  inflating: outputimages/ankan/2_0_4686.jpg  \n",
            "  inflating: outputimages/ankan/2_0_4711.jpg  \n",
            "  inflating: outputimages/ankan/3_0_3562.jpg  \n",
            "  inflating: outputimages/ankan/3_0_4035.jpg  \n",
            "  inflating: outputimages/ankan/3_0_4401.jpg  \n",
            "  inflating: outputimages/ankan/3_0_5695.jpg  \n",
            "  inflating: outputimages/ankan/3_0_7633.jpg  \n",
            "   creating: outputimages/arko/\n",
            "  inflating: outputimages/arko/1_0_2221.jpg  \n",
            "  inflating: outputimages/arko/1_0_3022.jpg  \n",
            "  inflating: outputimages/arko/1_0_3508.jpg  \n",
            "  inflating: outputimages/arko/1_0_5685.jpg  \n",
            "  inflating: outputimages/arko/1_0_5894.jpg  \n",
            "  inflating: outputimages/arko/2_0_1181.jpg  \n",
            "  inflating: outputimages/arko/2_0_1603.jpg  \n",
            "  inflating: outputimages/arko/2_0_2601.jpg  \n",
            "  inflating: outputimages/arko/2_0_609.jpg  \n",
            "  inflating: outputimages/arko/2_0_8820.jpg  \n",
            "   creating: outputimages/Avishek/\n",
            "  inflating: outputimages/Avishek/1_0_4405.jpg  \n",
            "  inflating: outputimages/Avishek/1_0_5468.jpg  \n",
            "  inflating: outputimages/Avishek/1_0_76.jpg  \n",
            "  inflating: outputimages/Avishek/1_0_9509.jpg  \n",
            "  inflating: outputimages/Avishek/1_0_9798.jpg  \n",
            "  inflating: outputimages/Avishek/2_0_2151.jpg  \n",
            "  inflating: outputimages/Avishek/2_0_378.jpg  \n",
            "  inflating: outputimages/Avishek/2_0_4946.jpg  \n",
            "  inflating: outputimages/Avishek/2_0_625.jpg  \n",
            "  inflating: outputimages/Avishek/2_0_8435.jpg  \n",
            "  inflating: outputimages/Avishek/3_0_2325.jpg  \n",
            "  inflating: outputimages/Avishek/3_0_303.jpg  \n",
            "  inflating: outputimages/Avishek/3_0_5498.jpg  \n",
            "  inflating: outputimages/Avishek/3_0_6720.jpg  \n",
            "  inflating: outputimages/Avishek/3_0_6936.jpg  \n",
            "  inflating: outputimages/Avishek/4_0_2310.jpg  \n",
            "  inflating: outputimages/Avishek/4_0_4813.jpg  \n",
            "  inflating: outputimages/Avishek/4_0_7648.jpg  \n",
            "  inflating: outputimages/Avishek/4_0_859.jpg  \n",
            "  inflating: outputimages/Avishek/4_0_898.jpg  \n",
            "   creating: outputimages/dks/\n",
            "  inflating: outputimages/dks/1_0_1894.jpg  \n",
            "  inflating: outputimages/dks/1_0_5989.jpg  \n",
            "  inflating: outputimages/dks/1_0_6653.jpg  \n",
            "  inflating: outputimages/dks/1_0_7463.jpg  \n",
            "  inflating: outputimages/dks/1_0_9434.jpg  \n",
            "  inflating: outputimages/dks/2_0_139.jpg  \n",
            "  inflating: outputimages/dks/2_0_3183.jpg  \n",
            "  inflating: outputimages/dks/2_0_3818.jpg  \n",
            "  inflating: outputimages/dks/2_0_6190.jpg  \n",
            "  inflating: outputimages/dks/2_0_9234.jpg  \n",
            "   creating: outputimages/samrat/\n",
            "  inflating: outputimages/samrat/1_0_130.jpg  \n",
            "  inflating: outputimages/samrat/1_0_1845.jpg  \n",
            "  inflating: outputimages/samrat/1_0_2525.jpg  \n",
            "  inflating: outputimages/samrat/1_0_4325.jpg  \n",
            "  inflating: outputimages/samrat/1_0_4507.jpg  \n",
            "  inflating: outputimages/samrat/2_0_1192.jpg  \n",
            "  inflating: outputimages/samrat/2_0_666.jpg  \n",
            "  inflating: outputimages/samrat/2_0_7076.jpg  \n",
            "  inflating: outputimages/samrat/2_0_7933.jpg  \n",
            "  inflating: outputimages/samrat/2_0_7952.jpg  \n",
            "  inflating: outputimages/samrat/3_0_3811.jpg  \n",
            "  inflating: outputimages/samrat/3_0_7766.jpg  \n",
            "  inflating: outputimages/samrat/3_0_8635.jpg  \n",
            "  inflating: outputimages/samrat/3_0_9783.jpg  \n",
            "  inflating: outputimages/samrat/3_0_9958.jpg  \n",
            "  inflating: outputimages/samrat/4_0_1000.jpg  \n",
            "  inflating: outputimages/samrat/4_0_1704.jpg  \n",
            "  inflating: outputimages/samrat/4_0_6940.jpg  \n",
            "  inflating: outputimages/samrat/4_0_7197.jpg  \n",
            "  inflating: outputimages/samrat/4_0_8837.jpg  \n",
            "   creating: outputimages/srs/\n",
            "  inflating: outputimages/srs/1_0_2026.jpg  \n",
            "  inflating: outputimages/srs/1_0_2161.jpg  \n",
            "  inflating: outputimages/srs/1_0_3465.jpg  \n",
            "  inflating: outputimages/srs/1_0_3824.jpg  \n",
            "  inflating: outputimages/srs/1_0_7994.jpg  \n",
            "  inflating: outputimages/srs/2_0_3906.jpg  \n",
            "  inflating: outputimages/srs/2_0_7414.jpg  \n",
            "  inflating: outputimages/srs/2_0_8176.jpg  \n",
            "  inflating: outputimages/srs/2_0_9132.jpg  \n",
            "  inflating: outputimages/srs/2_0_9578.jpg  \n",
            "  inflating: outputimages/srs/3_0_3539.jpg  \n",
            "  inflating: outputimages/srs/3_0_3621.jpg  \n",
            "  inflating: outputimages/srs/3_0_4099.jpg  \n",
            "  inflating: outputimages/srs/3_0_6187.jpg  \n",
            "  inflating: outputimages/srs/3_0_8266.jpg  \n",
            "  inflating: outputimages/srs/4_0_2299.jpg  \n",
            "  inflating: outputimages/srs/4_0_2984.jpg  \n",
            "  inflating: outputimages/srs/4_0_3158.jpg  \n",
            "  inflating: outputimages/srs/4_0_4046.jpg  \n",
            "  inflating: outputimages/srs/4_0_7999.jpg  \n",
            "   creating: outputimages/susmita/\n",
            "  inflating: outputimages/susmita/1_0_2676.jpg  \n",
            "  inflating: outputimages/susmita/1_0_4323.jpg  \n",
            "  inflating: outputimages/susmita/1_0_6084.jpg  \n",
            "  inflating: outputimages/susmita/1_0_7703.jpg  \n",
            "  inflating: outputimages/susmita/1_0_9453.jpg  \n",
            "  inflating: outputimages/susmita/2_0_1509.jpg  \n",
            "  inflating: outputimages/susmita/2_0_2086.jpg  \n",
            "  inflating: outputimages/susmita/2_0_2522.jpg  \n",
            "  inflating: outputimages/susmita/2_0_5278.jpg  \n",
            "  inflating: outputimages/susmita/2_0_5529.jpg  \n",
            "  inflating: outputimages/susmita/3_0_1912.jpg  \n",
            "  inflating: outputimages/susmita/3_0_6547.jpg  \n",
            "  inflating: outputimages/susmita/3_0_7462.jpg  \n",
            "  inflating: outputimages/susmita/3_0_8606.jpg  \n",
            "  inflating: outputimages/susmita/3_0_9371.jpg  \n",
            "  inflating: outputimages/susmita/4_0_5259.jpg  \n",
            "  inflating: outputimages/susmita/4_0_5672.jpg  \n",
            "  inflating: outputimages/susmita/4_0_5691.jpg  \n",
            "  inflating: outputimages/susmita/4_0_7939.jpg  \n",
            "  inflating: outputimages/susmita/4_0_9125.jpg  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Print the Dataset Directory"
      ],
      "metadata": {
        "id": "ONIjbEIeQlyS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/outputimages\n",
        "!sudo apt-get install tree\n",
        "!tree"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3ZUAaPBQrsx",
        "outputId": "2e38f26c-a7f9-4149-ff35-f0d199bd41b9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/outputimages\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "tree is already the newest version (2.0.2-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 45 not upgraded.\n",
            "\u001b[01;34m.\u001b[0m\n",
            "├── \u001b[01;34mankan\u001b[0m\n",
            "│   ├── \u001b[01;35m1_0_1641.jpg\u001b[0m\n",
            "│   ├── \u001b[01;35m1_0_5373.jpg\u001b[0m\n",
            "│   ├── \u001b[01;35m1_0_7667.jpg\u001b[0m\n",
            "│   ├── \u001b[01;35m1_0_9120.jpg\u001b[0m\n",
            "│   ├── \u001b[01;35m1_0_9649.jpg\u001b[0m\n",
            "│   ├── \u001b[01;35m2_0_1309.jpg\u001b[0m\n",
            "│   ├── \u001b[01;35m2_0_2196.jpg\u001b[0m\n",
            "│   ├── \u001b[01;35m2_0_3780.jpg\u001b[0m\n",
            "│   ├── \u001b[01;35m2_0_4686.jpg\u001b[0m\n",
            "│   ├── \u001b[01;35m2_0_4711.jpg\u001b[0m\n",
            "│   ├── \u001b[01;35m3_0_3562.jpg\u001b[0m\n",
            "│   ├── \u001b[01;35m3_0_4035.jpg\u001b[0m\n",
            "│   ├── \u001b[01;35m3_0_4401.jpg\u001b[0m\n",
            "│   ├── \u001b[01;35m3_0_5695.jpg\u001b[0m\n",
            "│   └── \u001b[01;35m3_0_7633.jpg\u001b[0m\n",
            "├── \u001b[01;34marko\u001b[0m\n",
            "│   ├── \u001b[01;35m1_0_2221.jpg\u001b[0m\n",
            "│   ├── \u001b[01;35m1_0_3022.jpg\u001b[0m\n",
            "│   ├── \u001b[01;35m1_0_3508.jpg\u001b[0m\n",
            "│   ├── \u001b[01;35m1_0_5685.jpg\u001b[0m\n",
            "│   ├── \u001b[01;35m1_0_5894.jpg\u001b[0m\n",
            "│   ├── \u001b[01;35m2_0_1181.jpg\u001b[0m\n",
            "│   ├── \u001b[01;35m2_0_1603.jpg\u001b[0m\n",
            "│   ├── \u001b[01;35m2_0_2601.jpg\u001b[0m\n",
            "│   ├── \u001b[01;35m2_0_609.jpg\u001b[0m\n",
            "│   └── \u001b[01;35m2_0_8820.jpg\u001b[0m\n",
            "├── \u001b[01;34mAvishek\u001b[0m\n",
            "│   ├── \u001b[01;35m1_0_4405.jpg\u001b[0m\n",
            "│   ├── \u001b[01;35m1_0_5468.jpg\u001b[0m\n",
            "│   ├── \u001b[01;35m1_0_76.jpg\u001b[0m\n",
            "│   ├── \u001b[01;35m1_0_9509.jpg\u001b[0m\n",
            "│   ├── \u001b[01;35m1_0_9798.jpg\u001b[0m\n",
            "│   ├── \u001b[01;35m2_0_2151.jpg\u001b[0m\n",
            "│   ├── \u001b[01;35m2_0_378.jpg\u001b[0m\n",
            "│   ├── \u001b[01;35m2_0_4946.jpg\u001b[0m\n",
            "│   ├── \u001b[01;35m2_0_625.jpg\u001b[0m\n",
            "│   ├── \u001b[01;35m2_0_8435.jpg\u001b[0m\n",
            "│   ├── \u001b[01;35m3_0_2325.jpg\u001b[0m\n",
            "│   ├── \u001b[01;35m3_0_303.jpg\u001b[0m\n",
            "│   ├── \u001b[01;35m3_0_5498.jpg\u001b[0m\n",
            "│   ├── \u001b[01;35m3_0_6720.jpg\u001b[0m\n",
            "│   ├── \u001b[01;35m3_0_6936.jpg\u001b[0m\n",
            "│   ├── \u001b[01;35m4_0_2310.jpg\u001b[0m\n",
            "│   ├── \u001b[01;35m4_0_4813.jpg\u001b[0m\n",
            "│   ├── \u001b[01;35m4_0_7648.jpg\u001b[0m\n",
            "│   ├── \u001b[01;35m4_0_859.jpg\u001b[0m\n",
            "│   └── \u001b[01;35m4_0_898.jpg\u001b[0m\n",
            "├── \u001b[01;34mdks\u001b[0m\n",
            "│   ├── \u001b[01;35m1_0_1894.jpg\u001b[0m\n",
            "│   ├── \u001b[01;35m1_0_5989.jpg\u001b[0m\n",
            "│   ├── \u001b[01;35m1_0_6653.jpg\u001b[0m\n",
            "│   ├── \u001b[01;35m1_0_7463.jpg\u001b[0m\n",
            "│   ├── \u001b[01;35m1_0_9434.jpg\u001b[0m\n",
            "│   ├── \u001b[01;35m2_0_139.jpg\u001b[0m\n",
            "│   ├── \u001b[01;35m2_0_3183.jpg\u001b[0m\n",
            "│   ├── \u001b[01;35m2_0_3818.jpg\u001b[0m\n",
            "│   ├── \u001b[01;35m2_0_6190.jpg\u001b[0m\n",
            "│   └── \u001b[01;35m2_0_9234.jpg\u001b[0m\n",
            "├── \u001b[01;34msamrat\u001b[0m\n",
            "│   ├── \u001b[01;35m1_0_130.jpg\u001b[0m\n",
            "│   ├── \u001b[01;35m1_0_1845.jpg\u001b[0m\n",
            "│   ├── \u001b[01;35m1_0_2525.jpg\u001b[0m\n",
            "│   ├── \u001b[01;35m1_0_4325.jpg\u001b[0m\n",
            "│   ├── \u001b[01;35m1_0_4507.jpg\u001b[0m\n",
            "│   ├── \u001b[01;35m2_0_1192.jpg\u001b[0m\n",
            "│   ├── \u001b[01;35m2_0_666.jpg\u001b[0m\n",
            "│   ├── \u001b[01;35m2_0_7076.jpg\u001b[0m\n",
            "│   ├── \u001b[01;35m2_0_7933.jpg\u001b[0m\n",
            "│   ├── \u001b[01;35m2_0_7952.jpg\u001b[0m\n",
            "│   ├── \u001b[01;35m3_0_3811.jpg\u001b[0m\n",
            "│   ├── \u001b[01;35m3_0_7766.jpg\u001b[0m\n",
            "│   ├── \u001b[01;35m3_0_8635.jpg\u001b[0m\n",
            "│   ├── \u001b[01;35m3_0_9783.jpg\u001b[0m\n",
            "│   ├── \u001b[01;35m3_0_9958.jpg\u001b[0m\n",
            "│   ├── \u001b[01;35m4_0_1000.jpg\u001b[0m\n",
            "│   ├── \u001b[01;35m4_0_1704.jpg\u001b[0m\n",
            "│   ├── \u001b[01;35m4_0_6940.jpg\u001b[0m\n",
            "│   ├── \u001b[01;35m4_0_7197.jpg\u001b[0m\n",
            "│   └── \u001b[01;35m4_0_8837.jpg\u001b[0m\n",
            "├── \u001b[01;34msrs\u001b[0m\n",
            "│   ├── \u001b[01;35m1_0_2026.jpg\u001b[0m\n",
            "│   ├── \u001b[01;35m1_0_2161.jpg\u001b[0m\n",
            "│   ├── \u001b[01;35m1_0_3465.jpg\u001b[0m\n",
            "│   ├── \u001b[01;35m1_0_3824.jpg\u001b[0m\n",
            "│   ├── \u001b[01;35m1_0_7994.jpg\u001b[0m\n",
            "│   ├── \u001b[01;35m2_0_3906.jpg\u001b[0m\n",
            "│   ├── \u001b[01;35m2_0_7414.jpg\u001b[0m\n",
            "│   ├── \u001b[01;35m2_0_8176.jpg\u001b[0m\n",
            "│   ├── \u001b[01;35m2_0_9132.jpg\u001b[0m\n",
            "│   ├── \u001b[01;35m2_0_9578.jpg\u001b[0m\n",
            "│   ├── \u001b[01;35m3_0_3539.jpg\u001b[0m\n",
            "│   ├── \u001b[01;35m3_0_3621.jpg\u001b[0m\n",
            "│   ├── \u001b[01;35m3_0_4099.jpg\u001b[0m\n",
            "│   ├── \u001b[01;35m3_0_6187.jpg\u001b[0m\n",
            "│   ├── \u001b[01;35m3_0_8266.jpg\u001b[0m\n",
            "│   ├── \u001b[01;35m4_0_2299.jpg\u001b[0m\n",
            "│   ├── \u001b[01;35m4_0_2984.jpg\u001b[0m\n",
            "│   ├── \u001b[01;35m4_0_3158.jpg\u001b[0m\n",
            "│   ├── \u001b[01;35m4_0_4046.jpg\u001b[0m\n",
            "│   └── \u001b[01;35m4_0_7999.jpg\u001b[0m\n",
            "└── \u001b[01;34msusmita\u001b[0m\n",
            "    ├── \u001b[01;35m1_0_2676.jpg\u001b[0m\n",
            "    ├── \u001b[01;35m1_0_4323.jpg\u001b[0m\n",
            "    ├── \u001b[01;35m1_0_6084.jpg\u001b[0m\n",
            "    ├── \u001b[01;35m1_0_7703.jpg\u001b[0m\n",
            "    ├── \u001b[01;35m1_0_9453.jpg\u001b[0m\n",
            "    ├── \u001b[01;35m2_0_1509.jpg\u001b[0m\n",
            "    ├── \u001b[01;35m2_0_2086.jpg\u001b[0m\n",
            "    ├── \u001b[01;35m2_0_2522.jpg\u001b[0m\n",
            "    ├── \u001b[01;35m2_0_5278.jpg\u001b[0m\n",
            "    ├── \u001b[01;35m2_0_5529.jpg\u001b[0m\n",
            "    ├── \u001b[01;35m3_0_1912.jpg\u001b[0m\n",
            "    ├── \u001b[01;35m3_0_6547.jpg\u001b[0m\n",
            "    ├── \u001b[01;35m3_0_7462.jpg\u001b[0m\n",
            "    ├── \u001b[01;35m3_0_8606.jpg\u001b[0m\n",
            "    ├── \u001b[01;35m3_0_9371.jpg\u001b[0m\n",
            "    ├── \u001b[01;35m4_0_5259.jpg\u001b[0m\n",
            "    ├── \u001b[01;35m4_0_5672.jpg\u001b[0m\n",
            "    ├── \u001b[01;35m4_0_5691.jpg\u001b[0m\n",
            "    ├── \u001b[01;35m4_0_7939.jpg\u001b[0m\n",
            "    └── \u001b[01;35m4_0_9125.jpg\u001b[0m\n",
            "\n",
            "7 directories, 115 files\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "7912AFVNRNQ7",
        "outputId": "fc1b3f54-10a1-44ea-f32c-582e159086ed"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/outputimages'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tree -d"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "plIRMJztRRY-",
        "outputId": "30dd0097-0179-4095-e606-451aa3cf3351"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[01;34m.\u001b[0m\n",
            "├── \u001b[01;34mankan\u001b[0m\n",
            "├── \u001b[01;34marko\u001b[0m\n",
            "├── \u001b[01;34mAvishek\u001b[0m\n",
            "├── \u001b[01;34mdks\u001b[0m\n",
            "├── \u001b[01;34msamrat\u001b[0m\n",
            "├── \u001b[01;34msrs\u001b[0m\n",
            "└── \u001b[01;34msusmita\u001b[0m\n",
            "\n",
            "7 directories\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Dataset"
      ],
      "metadata": {
        "id": "xU5fjwnDSOf3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q numpy"
      ],
      "metadata": {
        "id": "v4ZSq_qpTeff"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "\n",
        "# Set up GPU\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "  try:\n",
        "    for gpu in gpus:\n",
        "      tf.config.experimental.set_memory_growth(gpu, True)\n",
        "  except RuntimeError as e:\n",
        "    print(e)\n",
        "\n",
        "# Data preprocessing\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest',\n",
        "    validation_split=0.2)  # using 20% of data for validation\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    '/content/outputimages',  # this should be the path to your dataset\n",
        "    target_size=(64, 64),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='training')\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    '/content/outputimages',\n",
        "    target_size=(64, 64),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='validation')\n",
        "\n",
        "# Model architecture\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3), kernel_regularizer=l2(0.01)),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(2, 2),\n",
        "\n",
        "    Conv2D(64, (3, 3), activation='relu', kernel_regularizer=l2(0.01)),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(2, 2),\n",
        "\n",
        "    Conv2D(128, (3, 3), activation='relu', kernel_regularizer=l2(0.01)),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(2, 2),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu', kernel_regularizer=l2(0.01)),\n",
        "    Dropout(0.5),\n",
        "    Dense(len(train_generator.class_indices), activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer=Adam(lr=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Model summary\n",
        "model.summary()\n",
        "\n",
        "# Calculate steps per epoch taking care of edge cases\n",
        "steps_per_epoch = np.maximum(1, train_generator.samples // train_generator.batch_size)\n",
        "validation_steps = np.maximum(1, validation_generator.samples // validation_generator.batch_size)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    epochs=50,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_steps)\n",
        "\n",
        "# Save the model\n",
        "model.save('face_recognition_model.h5')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pidlzdXYSSJi",
        "outputId": "4527c821-6150-49a0-8a58-b4454b6cde5b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 92 images belonging to 7 classes.\n",
            "Found 23 images belonging to 7 classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_6 (Conv2D)           (None, 62, 62, 32)        896       \n",
            "                                                                 \n",
            " batch_normalization_6 (Bat  (None, 62, 62, 32)        128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPoolin  (None, 31, 31, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 29, 29, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization_7 (Bat  (None, 29, 29, 64)        256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPoolin  (None, 14, 14, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 12, 12, 128)       73856     \n",
            "                                                                 \n",
            " batch_normalization_8 (Bat  (None, 12, 12, 128)       512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_8 (MaxPoolin  (None, 6, 6, 128)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 4608)              0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 512)               2359808   \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 7)                 3591      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2457543 (9.37 MB)\n",
            "Trainable params: 2457095 (9.37 MB)\n",
            "Non-trainable params: 448 (1.75 KB)\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "2/2 [==============================] - 3s 529ms/step - loss: 15.6945 - accuracy: 0.1667 - val_loss: 12.4589 - val_accuracy: 0.1739\n",
            "Epoch 2/50\n",
            "2/2 [==============================] - 0s 148ms/step - loss: 12.7315 - accuracy: 0.5625 - val_loss: 12.3688 - val_accuracy: 0.1739\n",
            "Epoch 3/50\n",
            "2/2 [==============================] - 0s 141ms/step - loss: 13.8214 - accuracy: 0.4667 - val_loss: 12.3953 - val_accuracy: 0.1739\n",
            "Epoch 4/50\n",
            "2/2 [==============================] - 0s 136ms/step - loss: 11.9204 - accuracy: 0.7167 - val_loss: 12.5086 - val_accuracy: 0.1739\n",
            "Epoch 5/50\n",
            "2/2 [==============================] - 0s 133ms/step - loss: 12.4528 - accuracy: 0.6833 - val_loss: 12.4716 - val_accuracy: 0.1739\n",
            "Epoch 6/50\n",
            "2/2 [==============================] - 0s 146ms/step - loss: 11.4506 - accuracy: 0.8333 - val_loss: 12.2626 - val_accuracy: 0.1739\n",
            "Epoch 7/50\n",
            "2/2 [==============================] - 0s 135ms/step - loss: 11.8160 - accuracy: 0.7344 - val_loss: 12.2512 - val_accuracy: 0.2174\n",
            "Epoch 8/50\n",
            "2/2 [==============================] - 0s 123ms/step - loss: 11.8468 - accuracy: 0.7500 - val_loss: 12.1433 - val_accuracy: 0.2609\n",
            "Epoch 9/50\n",
            "2/2 [==============================] - 0s 138ms/step - loss: 11.8856 - accuracy: 0.7031 - val_loss: 12.1723 - val_accuracy: 0.2174\n",
            "Epoch 10/50\n",
            "2/2 [==============================] - 0s 139ms/step - loss: 10.6737 - accuracy: 0.9219 - val_loss: 11.9360 - val_accuracy: 0.2609\n",
            "Epoch 11/50\n",
            "2/2 [==============================] - 0s 141ms/step - loss: 11.0993 - accuracy: 0.8594 - val_loss: 11.9414 - val_accuracy: 0.2609\n",
            "Epoch 12/50\n",
            "2/2 [==============================] - 0s 136ms/step - loss: 11.0422 - accuracy: 0.7656 - val_loss: 11.9147 - val_accuracy: 0.3043\n",
            "Epoch 13/50\n",
            "2/2 [==============================] - 0s 147ms/step - loss: 11.1539 - accuracy: 0.7833 - val_loss: 11.9448 - val_accuracy: 0.3913\n",
            "Epoch 14/50\n",
            "2/2 [==============================] - 0s 144ms/step - loss: 10.8240 - accuracy: 0.7656 - val_loss: 11.7930 - val_accuracy: 0.3478\n",
            "Epoch 15/50\n",
            "2/2 [==============================] - 0s 135ms/step - loss: 10.8062 - accuracy: 0.8333 - val_loss: 11.7773 - val_accuracy: 0.2609\n",
            "Epoch 16/50\n",
            "2/2 [==============================] - 0s 149ms/step - loss: 10.5686 - accuracy: 0.8000 - val_loss: 11.7857 - val_accuracy: 0.2609\n",
            "Epoch 17/50\n",
            "2/2 [==============================] - 0s 138ms/step - loss: 10.3050 - accuracy: 0.8667 - val_loss: 11.7249 - val_accuracy: 0.2174\n",
            "Epoch 18/50\n",
            "2/2 [==============================] - 0s 139ms/step - loss: 10.0970 - accuracy: 0.8750 - val_loss: 11.6146 - val_accuracy: 0.2609\n",
            "Epoch 19/50\n",
            "2/2 [==============================] - 0s 134ms/step - loss: 9.8725 - accuracy: 0.9333 - val_loss: 11.7394 - val_accuracy: 0.2609\n",
            "Epoch 20/50\n",
            "2/2 [==============================] - 0s 153ms/step - loss: 9.8612 - accuracy: 0.9333 - val_loss: 11.8232 - val_accuracy: 0.2609\n",
            "Epoch 21/50\n",
            "2/2 [==============================] - 0s 142ms/step - loss: 10.0746 - accuracy: 0.8438 - val_loss: 11.9747 - val_accuracy: 0.2609\n",
            "Epoch 22/50\n",
            "2/2 [==============================] - 0s 146ms/step - loss: 9.7929 - accuracy: 0.9167 - val_loss: 12.0505 - val_accuracy: 0.1739\n",
            "Epoch 23/50\n",
            "2/2 [==============================] - 0s 148ms/step - loss: 9.6392 - accuracy: 0.8750 - val_loss: 12.1548 - val_accuracy: 0.1739\n",
            "Epoch 24/50\n",
            "2/2 [==============================] - 0s 155ms/step - loss: 9.4449 - accuracy: 0.9531 - val_loss: 12.1613 - val_accuracy: 0.1739\n",
            "Epoch 25/50\n",
            "2/2 [==============================] - 0s 134ms/step - loss: 9.4344 - accuracy: 0.8500 - val_loss: 12.6285 - val_accuracy: 0.1739\n",
            "Epoch 26/50\n",
            "2/2 [==============================] - 0s 137ms/step - loss: 9.1432 - accuracy: 0.9500 - val_loss: 12.6337 - val_accuracy: 0.1739\n",
            "Epoch 27/50\n",
            "2/2 [==============================] - 0s 146ms/step - loss: 9.0034 - accuracy: 0.9500 - val_loss: 12.4745 - val_accuracy: 0.1739\n",
            "Epoch 28/50\n",
            "2/2 [==============================] - 0s 187ms/step - loss: 8.7471 - accuracy: 1.0000 - val_loss: 12.2789 - val_accuracy: 0.1739\n",
            "Epoch 29/50\n",
            "2/2 [==============================] - 0s 151ms/step - loss: 8.8264 - accuracy: 0.9167 - val_loss: 12.0141 - val_accuracy: 0.1739\n",
            "Epoch 30/50\n",
            "2/2 [==============================] - 0s 146ms/step - loss: 9.0178 - accuracy: 0.8906 - val_loss: 11.5627 - val_accuracy: 0.2174\n",
            "Epoch 31/50\n",
            "2/2 [==============================] - 0s 150ms/step - loss: 8.8076 - accuracy: 0.8906 - val_loss: 11.2514 - val_accuracy: 0.2174\n",
            "Epoch 32/50\n",
            "2/2 [==============================] - 0s 138ms/step - loss: 8.6799 - accuracy: 0.9000 - val_loss: 11.2446 - val_accuracy: 0.2609\n",
            "Epoch 33/50\n",
            "2/2 [==============================] - 0s 143ms/step - loss: 8.3341 - accuracy: 0.9667 - val_loss: 10.9827 - val_accuracy: 0.2609\n",
            "Epoch 34/50\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 8.4696 - accuracy: 0.8667 - val_loss: 10.9348 - val_accuracy: 0.2609\n",
            "Epoch 35/50\n",
            "2/2 [==============================] - 0s 150ms/step - loss: 8.1807 - accuracy: 0.9000 - val_loss: 10.6713 - val_accuracy: 0.2609\n",
            "Epoch 36/50\n",
            "2/2 [==============================] - 0s 139ms/step - loss: 8.1105 - accuracy: 0.9500 - val_loss: 10.3967 - val_accuracy: 0.3043\n",
            "Epoch 37/50\n",
            "2/2 [==============================] - 0s 137ms/step - loss: 8.0136 - accuracy: 0.9531 - val_loss: 10.1855 - val_accuracy: 0.2609\n",
            "Epoch 38/50\n",
            "2/2 [==============================] - 0s 136ms/step - loss: 8.5015 - accuracy: 0.8500 - val_loss: 10.2366 - val_accuracy: 0.3913\n",
            "Epoch 39/50\n",
            "2/2 [==============================] - 0s 142ms/step - loss: 7.6959 - accuracy: 0.9500 - val_loss: 10.3128 - val_accuracy: 0.3913\n",
            "Epoch 40/50\n",
            "2/2 [==============================] - 0s 144ms/step - loss: 7.6647 - accuracy: 0.9667 - val_loss: 10.5957 - val_accuracy: 0.3913\n",
            "Epoch 41/50\n",
            "2/2 [==============================] - 0s 135ms/step - loss: 7.6446 - accuracy: 0.9667 - val_loss: 10.7060 - val_accuracy: 0.3478\n",
            "Epoch 42/50\n",
            "2/2 [==============================] - 0s 140ms/step - loss: 7.5892 - accuracy: 0.9531 - val_loss: 10.5805 - val_accuracy: 0.3913\n",
            "Epoch 43/50\n",
            "2/2 [==============================] - 0s 139ms/step - loss: 7.4452 - accuracy: 0.9531 - val_loss: 10.6545 - val_accuracy: 0.3913\n",
            "Epoch 44/50\n",
            "2/2 [==============================] - 0s 152ms/step - loss: 7.3162 - accuracy: 0.9844 - val_loss: 10.6062 - val_accuracy: 0.3478\n",
            "Epoch 45/50\n",
            "2/2 [==============================] - 0s 151ms/step - loss: 7.6497 - accuracy: 0.9000 - val_loss: 10.6769 - val_accuracy: 0.3043\n",
            "Epoch 46/50\n",
            "2/2 [==============================] - 0s 135ms/step - loss: 7.5237 - accuracy: 0.9062 - val_loss: 10.6119 - val_accuracy: 0.3043\n",
            "Epoch 47/50\n",
            "2/2 [==============================] - 0s 136ms/step - loss: 7.4089 - accuracy: 0.9062 - val_loss: 10.7551 - val_accuracy: 0.2609\n",
            "Epoch 48/50\n",
            "2/2 [==============================] - 0s 129ms/step - loss: 6.8895 - accuracy: 0.9667 - val_loss: 10.7943 - val_accuracy: 0.2609\n",
            "Epoch 49/50\n",
            "2/2 [==============================] - 0s 138ms/step - loss: 6.9786 - accuracy: 0.9219 - val_loss: 11.0793 - val_accuracy: 0.2609\n",
            "Epoch 50/50\n",
            "2/2 [==============================] - 0s 146ms/step - loss: 6.9114 - accuracy: 0.9844 - val_loss: 11.1815 - val_accuracy: 0.1739\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation"
      ],
      "metadata": {
        "id": "gWmHWaDfUoor"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot training & validation accuracy values\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "id": "-9czU8lrUbIf",
        "outputId": "c6509a34-28c8-4508-f64c-b3f33733240a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Changing LR, BS and Others Parameters"
      ],
      "metadata": {
        "id": "LJ0JLvUcg2MN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Increasing Validation Split"
      ],
      "metadata": {
        "id": "uZy0Ws_0hHYZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Infrence is still low - so Preprocessed the data with Train and Validation Set"
      ],
      "metadata": {
        "id": "8l9O2qSLhZ_1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Train and Load Best Model**"
      ],
      "metadata": {
        "id": "KE5sDRlcifig"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference"
      ],
      "metadata": {
        "id": "xMzK8yImUugV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Increase Model Performance**"
      ],
      "metadata": {
        "id": "u0ZEzQeeVLCX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "\n",
        "# Set up GPU\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "  try:\n",
        "    for gpu in gpus:\n",
        "      tf.config.experimental.set_memory_growth(gpu, True)\n",
        "  except RuntimeError as e:\n",
        "    print(e)\n",
        "\n",
        "# Data preprocessing with augmented ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=40,  # Increased for more variation\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.3,  # Increased shear\n",
        "    zoom_range=0.3,   # Increased zoom\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest',\n",
        "    validation_split=0.25)  # Increased validation set\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    '/content/outputimages',  # Adjust as per your dataset path\n",
        "    target_size=(64, 64),\n",
        "    batch_size=16,  # Reduced batch size for more updates\n",
        "    class_mode='categorical',\n",
        "    subset='training')\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    '/content/outputimages',\n",
        "    target_size=(64, 64),\n",
        "    batch_size=16,\n",
        "    class_mode='categorical',\n",
        "    subset='validation')\n",
        "\n",
        "# Enhanced Model architecture with additional layers and dropout\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Dropout(0.1),  # Added dropout\n",
        "\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Dropout(0.2),  # Increased dropout\n",
        "\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Dropout(0.3),  # Increased dropout\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dropout(0.5),  # Retained dropout\n",
        "    Dense(len(train_generator.class_indices), activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile model with updated learning rate parameter\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Model summary\n",
        "model.summary()\n",
        "\n",
        "# Calculate steps per epoch and validation steps, taking care of edge cases\n",
        "steps_per_epoch = np.maximum(1, train_generator.samples // train_generator.batch_size)\n",
        "validation_steps = np.maximum(1, validation_generator.samples // validation_generator.batch_size)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    epochs=50,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_steps)\n",
        "\n",
        "# Save the model in updated format\n",
        "model.save('face_recognition_model.keras')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VujU6v3aVKo-",
        "outputId": "8e71f640-7c75-4d6d-d107-fad6961820a7"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 88 images belonging to 7 classes.\n",
            "Found 27 images belonging to 7 classes.\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_9 (Conv2D)           (None, 62, 62, 32)        896       \n",
            "                                                                 \n",
            " batch_normalization_9 (Bat  (None, 62, 62, 32)        128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_9 (MaxPoolin  (None, 31, 31, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 31, 31, 32)        0         \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 29, 29, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization_10 (Ba  (None, 29, 29, 64)        256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling2d_10 (MaxPooli  (None, 14, 14, 64)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 14, 14, 64)        0         \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 12, 12, 128)       73856     \n",
            "                                                                 \n",
            " batch_normalization_11 (Ba  (None, 12, 12, 128)       512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling2d_11 (MaxPooli  (None, 6, 6, 128)         0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 6, 6, 128)         0         \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 4608)              0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 512)               2359808   \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 7)                 3591      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2457543 (9.37 MB)\n",
            "Trainable params: 2457095 (9.37 MB)\n",
            "Non-trainable params: 448 (1.75 KB)\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "5/5 [==============================] - 3s 165ms/step - loss: 4.1270 - accuracy: 0.1667 - val_loss: 1.9261 - val_accuracy: 0.1875\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 3.1789 - accuracy: 0.2917 - val_loss: 1.9509 - val_accuracy: 0.1250\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 0s 49ms/step - loss: 3.0576 - accuracy: 0.3375 - val_loss: 1.9380 - val_accuracy: 0.2500\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 0s 50ms/step - loss: 2.5394 - accuracy: 0.3500 - val_loss: 2.0037 - val_accuracy: 0.1250\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 2.5969 - accuracy: 0.3194 - val_loss: 1.9165 - val_accuracy: 0.1250\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 0s 55ms/step - loss: 2.1290 - accuracy: 0.4861 - val_loss: 2.1097 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 0s 52ms/step - loss: 2.2075 - accuracy: 0.4167 - val_loss: 2.0733 - val_accuracy: 0.0625\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 0s 50ms/step - loss: 2.0146 - accuracy: 0.5000 - val_loss: 2.1427 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 0s 49ms/step - loss: 1.6251 - accuracy: 0.5500 - val_loss: 2.1819 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 0s 48ms/step - loss: 1.5688 - accuracy: 0.6000 - val_loss: 2.2340 - val_accuracy: 0.0625\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 0s 51ms/step - loss: 1.8370 - accuracy: 0.5125 - val_loss: 2.3665 - val_accuracy: 0.1250\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 0s 48ms/step - loss: 1.6496 - accuracy: 0.6111 - val_loss: 2.6325 - val_accuracy: 0.0625\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 0s 51ms/step - loss: 1.7663 - accuracy: 0.5500 - val_loss: 2.4434 - val_accuracy: 0.0625\n",
            "Epoch 14/50\n",
            "5/5 [==============================] - 0s 49ms/step - loss: 1.4086 - accuracy: 0.5375 - val_loss: 2.4521 - val_accuracy: 0.1250\n",
            "Epoch 15/50\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 1.8989 - accuracy: 0.5000 - val_loss: 2.8560 - val_accuracy: 0.1250\n",
            "Epoch 16/50\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 1.6756 - accuracy: 0.4583 - val_loss: 2.6114 - val_accuracy: 0.1250\n",
            "Epoch 17/50\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 1.2509 - accuracy: 0.5833 - val_loss: 3.0581 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/50\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 1.8449 - accuracy: 0.5000 - val_loss: 2.8701 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/50\n",
            "5/5 [==============================] - 0s 50ms/step - loss: 1.3590 - accuracy: 0.6000 - val_loss: 2.4840 - val_accuracy: 0.1250\n",
            "Epoch 20/50\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 1.2794 - accuracy: 0.6389 - val_loss: 3.1860 - val_accuracy: 0.0625\n",
            "Epoch 21/50\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.9407 - accuracy: 0.6389 - val_loss: 3.1322 - val_accuracy: 0.0625\n",
            "Epoch 22/50\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 1.5807 - accuracy: 0.5833 - val_loss: 2.9673 - val_accuracy: 0.0625\n",
            "Epoch 23/50\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 1.0534 - accuracy: 0.6806 - val_loss: 3.6233 - val_accuracy: 0.0625\n",
            "Epoch 24/50\n",
            "5/5 [==============================] - 0s 49ms/step - loss: 1.0086 - accuracy: 0.6875 - val_loss: 2.5492 - val_accuracy: 0.1875\n",
            "Epoch 25/50\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 1.2354 - accuracy: 0.6111 - val_loss: 3.5359 - val_accuracy: 0.1250\n",
            "Epoch 26/50\n",
            "5/5 [==============================] - 0s 49ms/step - loss: 0.9705 - accuracy: 0.6375 - val_loss: 3.5169 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/50\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.9565 - accuracy: 0.6944 - val_loss: 3.4045 - val_accuracy: 0.1250\n",
            "Epoch 28/50\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.9280 - accuracy: 0.6944 - val_loss: 4.8659 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/50\n",
            "5/5 [==============================] - 0s 52ms/step - loss: 1.4097 - accuracy: 0.5694 - val_loss: 4.9918 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/50\n",
            "5/5 [==============================] - 0s 48ms/step - loss: 1.6113 - accuracy: 0.5972 - val_loss: 4.9457 - val_accuracy: 0.0625\n",
            "Epoch 31/50\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.8875 - accuracy: 0.6944 - val_loss: 4.7818 - val_accuracy: 0.0625\n",
            "Epoch 32/50\n",
            "5/5 [==============================] - 0s 51ms/step - loss: 1.0748 - accuracy: 0.6528 - val_loss: 5.0473 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/50\n",
            "5/5 [==============================] - 0s 53ms/step - loss: 0.7548 - accuracy: 0.7361 - val_loss: 4.3382 - val_accuracy: 0.0625\n",
            "Epoch 34/50\n",
            "5/5 [==============================] - 0s 53ms/step - loss: 0.9632 - accuracy: 0.6667 - val_loss: 4.0673 - val_accuracy: 0.0625\n",
            "Epoch 35/50\n",
            "5/5 [==============================] - 0s 52ms/step - loss: 1.0370 - accuracy: 0.6750 - val_loss: 4.2438 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/50\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.9820 - accuracy: 0.7500 - val_loss: 3.0841 - val_accuracy: 0.1250\n",
            "Epoch 37/50\n",
            "5/5 [==============================] - 0s 51ms/step - loss: 0.8433 - accuracy: 0.7625 - val_loss: 5.1622 - val_accuracy: 0.0625\n",
            "Epoch 38/50\n",
            "5/5 [==============================] - 0s 50ms/step - loss: 1.2148 - accuracy: 0.6389 - val_loss: 3.6865 - val_accuracy: 0.1250\n",
            "Epoch 39/50\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.9680 - accuracy: 0.6111 - val_loss: 4.4107 - val_accuracy: 0.0625\n",
            "Epoch 40/50\n",
            "5/5 [==============================] - 0s 50ms/step - loss: 0.9008 - accuracy: 0.6667 - val_loss: 5.0805 - val_accuracy: 0.0625\n",
            "Epoch 41/50\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.9455 - accuracy: 0.7083 - val_loss: 5.0584 - val_accuracy: 0.0625\n",
            "Epoch 42/50\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 0.7236 - accuracy: 0.6944 - val_loss: 4.5954 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/50\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.8542 - accuracy: 0.7222 - val_loss: 4.8478 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/50\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.8387 - accuracy: 0.7500 - val_loss: 5.2525 - val_accuracy: 0.0625\n",
            "Epoch 45/50\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.7272 - accuracy: 0.7778 - val_loss: 4.7724 - val_accuracy: 0.0625\n",
            "Epoch 46/50\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 0.8361 - accuracy: 0.7083 - val_loss: 4.4145 - val_accuracy: 0.0625\n",
            "Epoch 47/50\n",
            "5/5 [==============================] - 0s 50ms/step - loss: 0.4949 - accuracy: 0.8375 - val_loss: 4.9684 - val_accuracy: 0.1250\n",
            "Epoch 48/50\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 0.8666 - accuracy: 0.7083 - val_loss: 5.5270 - val_accuracy: 0.0000e+00\n",
            "Epoch 49/50\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.7293 - accuracy: 0.7639 - val_loss: 3.5565 - val_accuracy: 0.1250\n",
            "Epoch 50/50\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.7518 - accuracy: 0.6944 - val_loss: 5.0226 - val_accuracy: 0.0000e+00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.regularizers import l1_l2\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "\n",
        "# Setup GPU\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "    except RuntimeError as e:\n",
        "        print(e)\n",
        "\n",
        "# Data augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.15,\n",
        "    height_shift_range=0.15,\n",
        "    shear_range=0.15,\n",
        "    zoom_range=0.15,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest',\n",
        "    validation_split=0.3)  # Increase validation split\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    '/content/outputimages',\n",
        "    target_size=(64, 64),\n",
        "    batch_size=16,\n",
        "    class_mode='categorical',\n",
        "    subset='training')\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    '/content/outputimages',\n",
        "    target_size=(64, 64),\n",
        "    batch_size=16,\n",
        "    class_mode='categorical',\n",
        "    subset='validation')\n",
        "\n",
        "# Model architecture\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3), kernel_regularizer=l1_l2(l1=0.01, l2=0.01)),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Dropout(0.1),\n",
        "\n",
        "    Conv2D(64, (3, 3), activation='relu', kernel_regularizer=l1_l2(l1=0.01, l2=0.01)),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Dropout(0.2),\n",
        "\n",
        "    Conv2D(128, (3, 3), activation='relu', kernel_regularizer=l1_l2(l1=0.01, l2=0.01)),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(len(train_generator.class_indices), activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile model with learning rate adjustment\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Callbacks\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='min')\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, verbose=1, mode='min', min_lr=0.00001)\n",
        "\n",
        "# Model training\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=np.maximum(1, train_generator.samples // train_generator.batch_size),\n",
        "    epochs=50,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=np.maximum(1, validation_generator.samples // validation_generator.batch_size),\n",
        "    callbacks=[early_stopping, reduce_lr])\n",
        "\n",
        "# Save the model\n",
        "model.save('face_recognition_model.keras')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_cMfoLCNWXz3",
        "outputId": "e22b1a79-a812-47f7-cd30-c880090ac449"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 81 images belonging to 7 classes.\n",
            "Found 34 images belonging to 7 classes.\n",
            "Epoch 1/50\n",
            "5/5 [==============================] - 3s 150ms/step - loss: 35.4968 - accuracy: 0.2000 - val_loss: 33.3443 - val_accuracy: 0.1875 - lr: 1.0000e-04\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 34.8330 - accuracy: 0.2615 - val_loss: 33.2823 - val_accuracy: 0.2188 - lr: 1.0000e-04\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 34.7674 - accuracy: 0.3231 - val_loss: 33.2459 - val_accuracy: 0.1562 - lr: 1.0000e-04\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 34.8612 - accuracy: 0.3231 - val_loss: 33.2134 - val_accuracy: 0.2188 - lr: 1.0000e-04\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 34.3215 - accuracy: 0.2615 - val_loss: 33.1664 - val_accuracy: 0.2188 - lr: 1.0000e-04\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 0s 55ms/step - loss: 33.3047 - accuracy: 0.3846 - val_loss: 33.1035 - val_accuracy: 0.1875 - lr: 1.0000e-04\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 0s 52ms/step - loss: 33.7538 - accuracy: 0.3625 - val_loss: 33.1167 - val_accuracy: 0.1875 - lr: 1.0000e-04\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 0s 49ms/step - loss: 34.0249 - accuracy: 0.2769 - val_loss: 33.0921 - val_accuracy: 0.1875 - lr: 1.0000e-04\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 33.0951 - accuracy: 0.4923 - val_loss: 33.1003 - val_accuracy: 0.1875 - lr: 1.0000e-04\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 0s 53ms/step - loss: 33.1681 - accuracy: 0.4000 - val_loss: 33.1012 - val_accuracy: 0.1875 - lr: 1.0000e-04\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 32.9722 - accuracy: 0.5077 - val_loss: 33.1301 - val_accuracy: 0.1562 - lr: 1.0000e-04\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 32.4084 - accuracy: 0.5846 - val_loss: 33.1218 - val_accuracy: 0.1875 - lr: 1.0000e-04\n",
            "Epoch 13/50\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 32.8043 - accuracy: 0.4490\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 32.6321 - accuracy: 0.4923 - val_loss: 33.1233 - val_accuracy: 0.1875 - lr: 1.0000e-04\n",
            "Epoch 14/50\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 32.7632 - accuracy: 0.4769 - val_loss: 33.2057 - val_accuracy: 0.1875 - lr: 2.0000e-05\n",
            "Epoch 15/50\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 32.6393 - accuracy: 0.5231 - val_loss: 33.3167 - val_accuracy: 0.1875 - lr: 2.0000e-05\n",
            "Epoch 16/50\n",
            "5/5 [==============================] - 0s 54ms/step - loss: 32.4133 - accuracy: 0.5385 - val_loss: 33.3382 - val_accuracy: 0.1875 - lr: 2.0000e-05\n",
            "Epoch 17/50\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 32.1466 - accuracy: 0.6462 - val_loss: 33.3953 - val_accuracy: 0.1875 - lr: 2.0000e-05\n",
            "Epoch 18/50\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 32.7623 - accuracy: 0.5102\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
            "5/5 [==============================] - 0s 49ms/step - loss: 32.7369 - accuracy: 0.5077 - val_loss: 33.6494 - val_accuracy: 0.1250 - lr: 2.0000e-05\n",
            "Epoch 18: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Inference**"
      ],
      "metadata": {
        "id": "DHeEOdyjhRr0"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CdDykfqKhRYI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the trained model\n",
        "model_path = '/content/outputimages/face_recognition_model.keras'\n",
        "model = load_model(model_path)\n",
        "\n",
        "# Function to load and preprocess an image\n",
        "def load_and_preprocess_image(img_path):\n",
        "    img = image.load_img(img_path, target_size=(64, 64))\n",
        "    img_tensor = image.img_to_array(img)\n",
        "    img_tensor = np.expand_dims(img_tensor, axis=0)  # Add batch dimension\n",
        "    img_tensor /= 255.0  # Normalize to [0,1]\n",
        "    return img_tensor\n",
        "\n",
        "# Replace 'test_image.jpg' with the path to your actual test image\n",
        "test_image_path = '/content/avishek.jpg'  # Update this path\n",
        "img_tensor = load_and_preprocess_image(test_image_path)\n",
        "\n",
        "# Predict the class of the image\n",
        "predictions = model.predict(img_tensor)\n",
        "predicted_class = np.argmax(predictions[0])\n",
        "print(\"Predicted class index:\", predicted_class)\n",
        "\n",
        "# Display the image\n",
        "plt.imshow(img_tensor[0])\n",
        "plt.title(f\"Predicted class index: {predicted_class}\")\n",
        "plt.show()\n",
        "\n",
        "# Optionally, if you know the class labels\n",
        "class_labels = {0: \"Class0\", 1: \"Class1\", 2: \"Class2\", 3: \"Class3\", 4: \"Class4\", 5: \"Class5\", 6: \"Class6\"}  # Update with actual class names\n",
        "predicted_label = class_labels[predicted_class]\n",
        "print(\"Predicted class label:\", predicted_label)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "id": "VIUdr2e-W04M",
        "outputId": "58ed9903-518e-43a7-f2e1-0d05ebc121d1"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 96ms/step\n",
            "Predicted class index: 4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted class label: Class4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dataset Split**"
      ],
      "metadata": {
        "id": "5tCZlELlmElm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import numpy as np\n",
        "\n",
        "def create_train_val_dirs(source_dir, target_dir, train_size=0.8):\n",
        "    classes = os.listdir(source_dir)\n",
        "    os.makedirs(target_dir, exist_ok=True)\n",
        "    os.makedirs(os.path.join(target_dir, 'train'), exist_ok=True)\n",
        "    os.makedirs(os.path.join(target_dir, 'val'), exist_ok=True)\n",
        "\n",
        "    for cls in classes:\n",
        "        os.makedirs(os.path.join(target_dir, 'train', cls), exist_ok=True)\n",
        "        os.makedirs(os.path.join(target_dir, 'val', cls), exist_ok=True)\n",
        "        images = os.listdir(os.path.join(source_dir, cls))\n",
        "        np.random.shuffle(images)\n",
        "        train_count = int(len(images) * train_size)\n",
        "\n",
        "        for img in images[:train_count]:\n",
        "            shutil.copy(os.path.join(source_dir, cls, img), os.path.join(target_dir, 'train', cls))\n",
        "        for img in images[train_count:]:\n",
        "            shutil.copy(os.path.join(source_dir, cls, img), os.path.join(target_dir, 'val', cls))\n",
        "\n",
        "# Usage\n",
        "source_directory = '/content/outputimages'  # Update with your original directory\n",
        "target_directory = '/content/dataset_split'  # Target directory to save split dataset\n",
        "create_train_val_dirs(source_directory, target_directory)\n"
      ],
      "metadata": {
        "id": "QTz-BbvYXFIt"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**K - Cross Fold Validations**"
      ],
      "metadata": {
        "id": "FC6N6ybChtts"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Directory containing your dataset\n",
        "dataset_directory = '/content/dataset_split/train'\n",
        "\n",
        "# Prepare data structure\n",
        "data = []\n",
        "labels = []\n",
        "classes = sorted(os.listdir(dataset_directory))\n",
        "label_map = {cls_name: idx for idx, cls_name in enumerate(classes)}\n",
        "\n",
        "# Collecting file paths and labels\n",
        "for cls_name in classes:\n",
        "    cls_folder = os.path.join(dataset_directory, cls_name)\n",
        "    for img_name in os.listdir(cls_folder):\n",
        "        img_path = os.path.join(cls_folder, img_name)\n",
        "        data.append(img_path)\n",
        "        labels.append(label_map[cls_name])\n",
        "\n",
        "# Convert labels to one-hot encoded format\n",
        "labels = tf.keras.utils.to_categorical(labels, num_classes=len(classes))\n",
        "\n",
        "# Define K-Fold Cross Validator\n",
        "num_folds = 5\n",
        "kfold = KFold(n_splits=num_folds, shuffle=True)\n"
      ],
      "metadata": {
        "id": "1OlVEcRuZWHh"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def load_image(file_path, label):\n",
        "    # Read the image file\n",
        "    img = tf.io.read_file(file_path)\n",
        "    # Decode the image\n",
        "    img = tf.image.decode_jpeg(img, channels=3)\n",
        "    # Resize the image to the target size (64x64 in this case)\n",
        "    img = tf.image.resize(img, [64, 64])\n",
        "    # Normalize the image pixels to [0, 1]\n",
        "    img = img / 255.0\n",
        "    return img, label\n"
      ],
      "metadata": {
        "id": "eDnLSFhSZ7mR"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Function to create the model (as previously defined)\n",
        "def create_model():\n",
        "    model = Sequential([\n",
        "        Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3), kernel_regularizer=l1_l2(l1=0.01, l2=0.01)),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling2D(2, 2),\n",
        "        Dropout(0.1),\n",
        "\n",
        "        Conv2D(64, (3, 3), activation='relu', kernel_regularizer=l1_l2(l1=0.01, l2=0.01)),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling2D(2, 2),\n",
        "        Dropout(0.2),\n",
        "\n",
        "        Conv2D(128, (3, 3), activation='relu', kernel_regularizer=l1_l2(l1=0.01, l2=0.01)),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling2D(2, 2),\n",
        "        Dropout(0.3),\n",
        "\n",
        "        Flatten(),\n",
        "        Dense(512, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(8, activation='softmax')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Directory containing your dataset\n",
        "dataset_directory = '/content/dataset_split/train'\n",
        "data = []\n",
        "labels = []\n",
        "classes = sorted(os.listdir(dataset_directory))\n",
        "label_map = {cls_name: idx for idx, cls_name in enumerate(classes)}\n",
        "\n",
        "for cls_name in classes:\n",
        "    cls_folder = os.path.join(dataset_directory, cls_name)\n",
        "    for img_name in os.listdir(cls_folder):\n",
        "        img_path = os.path.join(cls_folder, img_name)\n",
        "        data.append(img_path)\n",
        "        labels.append(label_map[cls_name])\n",
        "\n",
        "labels = tf.keras.utils.to_categorical(labels, num_classes=len(classes))\n",
        "\n",
        "# K-Fold Cross-Validation setup\n",
        "num_folds = 5\n",
        "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
        "fold_no = 1\n",
        "acc_per_fold = []\n",
        "loss_per_fold = []\n",
        "\n",
        "for train, test in kfold.split(data, labels):\n",
        "    train_gen = ImageDataGenerator(rescale=1./255)\n",
        "    val_gen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "    train_data = tf.data.Dataset.from_tensor_slices((np.array(data)[train], labels[train]))\n",
        "    train_data = train_data.map(load_image).batch(16)\n",
        "\n",
        "    val_data = tf.data.Dataset.from_tensor_slices((np.array(data)[test], labels[test]))\n",
        "    val_data = val_data.map(load_image).batch(16)\n",
        "\n",
        "    model = create_model()\n",
        "    model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    history = model.fit(train_data, epochs=100, validation_data=val_data)\n",
        "\n",
        "    scores = model.evaluate(val_data)\n",
        "    acc_per_fold.append(scores[1] * 100)\n",
        "    loss_per_fold.append(scores[0])\n",
        "\n",
        "    fold_no += 1\n",
        "\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Score per fold')\n",
        "for i in range(len(acc_per_fold)):\n",
        "    print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Average scores for all folds:')\n",
        "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
        "print(f'> Loss: {np.mean(loss_per_fold)}')\n",
        "print('------------------------------------------------------------------------')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbrpP3YgZX-m",
        "outputId": "761e5e82-3f79-4372-e33e-51a7bdd0cfcc"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "6/6 [==============================] - 3s 121ms/step - loss: 36.8941 - accuracy: 0.0732 - val_loss: 33.2917 - val_accuracy: 0.2857\n",
            "Epoch 2/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 34.3129 - accuracy: 0.2317 - val_loss: 33.2904 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 33.8924 - accuracy: 0.4268 - val_loss: 33.3501 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 33.0669 - accuracy: 0.4756 - val_loss: 33.4556 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/100\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 33.0232 - accuracy: 0.5122 - val_loss: 33.5799 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 32.5688 - accuracy: 0.5488 - val_loss: 33.7265 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/100\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 32.6728 - accuracy: 0.4878 - val_loss: 33.9010 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/100\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 31.9262 - accuracy: 0.6463 - val_loss: 34.0919 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/100\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 31.6186 - accuracy: 0.6829 - val_loss: 34.2564 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 31.6256 - accuracy: 0.7317 - val_loss: 34.3972 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 31.3568 - accuracy: 0.8049 - val_loss: 34.5091 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 31.1721 - accuracy: 0.8415 - val_loss: 34.6175 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/100\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 30.9791 - accuracy: 0.8537 - val_loss: 34.7400 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/100\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 31.0258 - accuracy: 0.7561 - val_loss: 34.8372 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 30.9071 - accuracy: 0.8171 - val_loss: 34.9091 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/100\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 30.7578 - accuracy: 0.7805 - val_loss: 35.0074 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 30.6440 - accuracy: 0.8537 - val_loss: 35.1153 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 30.5021 - accuracy: 0.8537 - val_loss: 35.1579 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 30.3177 - accuracy: 0.9146 - val_loss: 35.1709 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 30.3090 - accuracy: 0.8537 - val_loss: 35.2305 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 30.2005 - accuracy: 0.8537 - val_loss: 35.2464 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 29.9821 - accuracy: 0.8780 - val_loss: 35.2632 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/100\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 29.8314 - accuracy: 0.9146 - val_loss: 35.2732 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/100\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 29.7528 - accuracy: 0.9390 - val_loss: 35.2546 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 29.7338 - accuracy: 0.8780 - val_loss: 35.2011 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 29.5771 - accuracy: 0.9756 - val_loss: 35.1098 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 29.3994 - accuracy: 0.9390 - val_loss: 35.0576 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 29.3893 - accuracy: 0.9268 - val_loss: 35.0254 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 29.2910 - accuracy: 0.9024 - val_loss: 34.9559 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 29.0459 - accuracy: 0.9878 - val_loss: 34.8995 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 29.0317 - accuracy: 0.9268 - val_loss: 34.8497 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 28.8619 - accuracy: 0.9634 - val_loss: 34.8289 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 28.7128 - accuracy: 0.9756 - val_loss: 34.7739 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 28.6318 - accuracy: 0.9634 - val_loss: 34.6676 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 28.5325 - accuracy: 0.9756 - val_loss: 34.4963 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 28.5017 - accuracy: 0.9390 - val_loss: 34.3164 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 28.3307 - accuracy: 0.9512 - val_loss: 34.2104 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/100\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 28.2414 - accuracy: 0.9634 - val_loss: 34.1131 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 28.0804 - accuracy: 0.9878 - val_loss: 33.9610 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 27.9802 - accuracy: 0.9756 - val_loss: 33.7999 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 27.7919 - accuracy: 0.9878 - val_loss: 33.6677 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 27.7037 - accuracy: 1.0000 - val_loss: 33.5336 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 27.6030 - accuracy: 0.9756 - val_loss: 33.3422 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 27.5302 - accuracy: 0.9512 - val_loss: 33.1682 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 27.3507 - accuracy: 0.9756 - val_loss: 33.0080 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 27.2412 - accuracy: 0.9756 - val_loss: 32.8428 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 27.0923 - accuracy: 1.0000 - val_loss: 32.6326 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 27.0290 - accuracy: 0.9512 - val_loss: 32.4411 - val_accuracy: 0.0000e+00\n",
            "Epoch 49/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 26.8485 - accuracy: 1.0000 - val_loss: 32.2508 - val_accuracy: 0.0000e+00\n",
            "Epoch 50/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 26.7556 - accuracy: 0.9756 - val_loss: 32.0651 - val_accuracy: 0.0000e+00\n",
            "Epoch 51/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 26.6761 - accuracy: 0.9634 - val_loss: 31.8545 - val_accuracy: 0.0000e+00\n",
            "Epoch 52/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 26.5573 - accuracy: 0.9756 - val_loss: 31.6253 - val_accuracy: 0.0000e+00\n",
            "Epoch 53/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 26.3673 - accuracy: 0.9756 - val_loss: 31.4096 - val_accuracy: 0.0000e+00\n",
            "Epoch 54/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 26.2436 - accuracy: 0.9878 - val_loss: 31.1811 - val_accuracy: 0.0000e+00\n",
            "Epoch 55/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 26.1260 - accuracy: 0.9634 - val_loss: 30.9584 - val_accuracy: 0.0000e+00\n",
            "Epoch 56/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 26.0013 - accuracy: 0.9878 - val_loss: 30.7562 - val_accuracy: 0.0000e+00\n",
            "Epoch 57/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 25.8439 - accuracy: 1.0000 - val_loss: 30.5324 - val_accuracy: 0.0476\n",
            "Epoch 58/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 25.7387 - accuracy: 0.9756 - val_loss: 30.2998 - val_accuracy: 0.0952\n",
            "Epoch 59/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 25.6269 - accuracy: 0.9756 - val_loss: 30.0302 - val_accuracy: 0.0952\n",
            "Epoch 60/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 25.4498 - accuracy: 1.0000 - val_loss: 29.7965 - val_accuracy: 0.0952\n",
            "Epoch 61/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 25.3248 - accuracy: 0.9878 - val_loss: 29.5656 - val_accuracy: 0.0952\n",
            "Epoch 62/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 25.2314 - accuracy: 0.9878 - val_loss: 29.3167 - val_accuracy: 0.1429\n",
            "Epoch 63/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 25.0460 - accuracy: 1.0000 - val_loss: 29.0879 - val_accuracy: 0.1429\n",
            "Epoch 64/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 24.9391 - accuracy: 1.0000 - val_loss: 28.8680 - val_accuracy: 0.1429\n",
            "Epoch 65/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 24.8563 - accuracy: 0.9756 - val_loss: 28.6616 - val_accuracy: 0.1429\n",
            "Epoch 66/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 24.6837 - accuracy: 0.9878 - val_loss: 28.4676 - val_accuracy: 0.1429\n",
            "Epoch 67/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 24.5830 - accuracy: 0.9756 - val_loss: 28.2440 - val_accuracy: 0.1429\n",
            "Epoch 68/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 24.4112 - accuracy: 0.9878 - val_loss: 28.0457 - val_accuracy: 0.1905\n",
            "Epoch 69/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 24.3160 - accuracy: 0.9634 - val_loss: 27.8684 - val_accuracy: 0.1905\n",
            "Epoch 70/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 24.1364 - accuracy: 1.0000 - val_loss: 27.6819 - val_accuracy: 0.1905\n",
            "Epoch 71/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 23.9950 - accuracy: 1.0000 - val_loss: 27.4864 - val_accuracy: 0.2381\n",
            "Epoch 72/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 23.9010 - accuracy: 0.9756 - val_loss: 27.2825 - val_accuracy: 0.2381\n",
            "Epoch 73/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 23.7625 - accuracy: 0.9878 - val_loss: 27.0445 - val_accuracy: 0.2381\n",
            "Epoch 74/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 23.5992 - accuracy: 0.9878 - val_loss: 26.7828 - val_accuracy: 0.2381\n",
            "Epoch 75/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 23.4835 - accuracy: 0.9878 - val_loss: 26.5208 - val_accuracy: 0.2857\n",
            "Epoch 76/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 23.3416 - accuracy: 0.9878 - val_loss: 26.2791 - val_accuracy: 0.2857\n",
            "Epoch 77/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 23.2174 - accuracy: 0.9756 - val_loss: 26.0590 - val_accuracy: 0.2857\n",
            "Epoch 78/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 23.0846 - accuracy: 0.9634 - val_loss: 25.8729 - val_accuracy: 0.2857\n",
            "Epoch 79/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 22.9252 - accuracy: 0.9878 - val_loss: 25.6952 - val_accuracy: 0.2857\n",
            "Epoch 80/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 22.7727 - accuracy: 1.0000 - val_loss: 25.5181 - val_accuracy: 0.2857\n",
            "Epoch 81/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 22.6509 - accuracy: 0.9878 - val_loss: 25.3433 - val_accuracy: 0.2857\n",
            "Epoch 82/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 22.5037 - accuracy: 1.0000 - val_loss: 25.1579 - val_accuracy: 0.2857\n",
            "Epoch 83/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 22.3638 - accuracy: 1.0000 - val_loss: 24.9676 - val_accuracy: 0.2857\n",
            "Epoch 84/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 22.2989 - accuracy: 0.9878 - val_loss: 24.7873 - val_accuracy: 0.2857\n",
            "Epoch 85/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 22.0956 - accuracy: 1.0000 - val_loss: 24.6137 - val_accuracy: 0.2857\n",
            "Epoch 86/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 21.9561 - accuracy: 0.9878 - val_loss: 24.4360 - val_accuracy: 0.2857\n",
            "Epoch 87/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 21.8055 - accuracy: 1.0000 - val_loss: 24.2669 - val_accuracy: 0.2857\n",
            "Epoch 88/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 21.6938 - accuracy: 0.9756 - val_loss: 24.0880 - val_accuracy: 0.2857\n",
            "Epoch 89/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 21.5333 - accuracy: 1.0000 - val_loss: 23.9113 - val_accuracy: 0.3333\n",
            "Epoch 90/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 21.4069 - accuracy: 0.9878 - val_loss: 23.7491 - val_accuracy: 0.3333\n",
            "Epoch 91/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 21.2993 - accuracy: 0.9756 - val_loss: 23.5954 - val_accuracy: 0.3333\n",
            "Epoch 92/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 21.1452 - accuracy: 0.9878 - val_loss: 23.4065 - val_accuracy: 0.3333\n",
            "Epoch 93/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 20.9809 - accuracy: 1.0000 - val_loss: 23.2315 - val_accuracy: 0.3333\n",
            "Epoch 94/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 20.8977 - accuracy: 0.9756 - val_loss: 23.0533 - val_accuracy: 0.3333\n",
            "Epoch 95/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 20.7152 - accuracy: 0.9878 - val_loss: 22.8728 - val_accuracy: 0.3333\n",
            "Epoch 96/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 20.5846 - accuracy: 0.9756 - val_loss: 22.6900 - val_accuracy: 0.3333\n",
            "Epoch 97/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 20.4265 - accuracy: 1.0000 - val_loss: 22.5097 - val_accuracy: 0.3333\n",
            "Epoch 98/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 20.3049 - accuracy: 0.9878 - val_loss: 22.3250 - val_accuracy: 0.3333\n",
            "Epoch 99/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 20.1520 - accuracy: 1.0000 - val_loss: 22.1383 - val_accuracy: 0.3333\n",
            "Epoch 100/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 20.0081 - accuracy: 1.0000 - val_loss: 21.9679 - val_accuracy: 0.3333\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 21.9679 - accuracy: 0.3333\n",
            "Epoch 1/100\n",
            "6/6 [==============================] - 3s 53ms/step - loss: 37.8468 - accuracy: 0.0366 - val_loss: 33.3662 - val_accuracy: 0.0476\n",
            "Epoch 2/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 34.7470 - accuracy: 0.1951 - val_loss: 33.3027 - val_accuracy: 0.0952\n",
            "Epoch 3/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 34.4073 - accuracy: 0.2561 - val_loss: 33.2611 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 34.1831 - accuracy: 0.3659 - val_loss: 33.2435 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 33.2635 - accuracy: 0.4634 - val_loss: 33.2346 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 33.2122 - accuracy: 0.5000 - val_loss: 33.2236 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 32.5205 - accuracy: 0.5122 - val_loss: 33.2022 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 32.1541 - accuracy: 0.6220 - val_loss: 33.1809 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 31.8962 - accuracy: 0.5976 - val_loss: 33.1592 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 32.0262 - accuracy: 0.6585 - val_loss: 33.1406 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 31.7498 - accuracy: 0.6463 - val_loss: 33.0896 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 31.4765 - accuracy: 0.7195 - val_loss: 33.0596 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 31.0854 - accuracy: 0.7805 - val_loss: 33.0515 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 31.0258 - accuracy: 0.7927 - val_loss: 33.0801 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 31.0395 - accuracy: 0.7683 - val_loss: 33.0599 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 30.9716 - accuracy: 0.7317 - val_loss: 33.0731 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 30.7441 - accuracy: 0.8415 - val_loss: 33.0427 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 30.7913 - accuracy: 0.7805 - val_loss: 32.9347 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 30.4840 - accuracy: 0.8902 - val_loss: 32.8823 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 30.3110 - accuracy: 0.8659 - val_loss: 32.8404 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 30.1825 - accuracy: 0.9024 - val_loss: 32.7680 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 29.9973 - accuracy: 0.9634 - val_loss: 32.6992 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 30.1206 - accuracy: 0.9024 - val_loss: 32.6171 - val_accuracy: 0.0476\n",
            "Epoch 24/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 30.0280 - accuracy: 0.9024 - val_loss: 32.4955 - val_accuracy: 0.0476\n",
            "Epoch 25/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 29.9168 - accuracy: 0.8659 - val_loss: 32.3783 - val_accuracy: 0.0476\n",
            "Epoch 26/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 29.5836 - accuracy: 0.9634 - val_loss: 32.2665 - val_accuracy: 0.0476\n",
            "Epoch 27/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 29.6635 - accuracy: 0.9024 - val_loss: 32.1550 - val_accuracy: 0.0476\n",
            "Epoch 28/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 29.5139 - accuracy: 0.9390 - val_loss: 32.0378 - val_accuracy: 0.0476\n",
            "Epoch 29/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 29.2950 - accuracy: 0.9634 - val_loss: 31.9423 - val_accuracy: 0.0476\n",
            "Epoch 30/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 29.2177 - accuracy: 0.9512 - val_loss: 31.8308 - val_accuracy: 0.0476\n",
            "Epoch 31/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 29.0971 - accuracy: 0.9634 - val_loss: 31.7134 - val_accuracy: 0.0476\n",
            "Epoch 32/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 29.1042 - accuracy: 0.9390 - val_loss: 31.6026 - val_accuracy: 0.0476\n",
            "Epoch 33/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 28.8702 - accuracy: 0.9756 - val_loss: 31.5369 - val_accuracy: 0.0476\n",
            "Epoch 34/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 28.7734 - accuracy: 0.9878 - val_loss: 31.4226 - val_accuracy: 0.0476\n",
            "Epoch 35/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 28.7473 - accuracy: 0.9390 - val_loss: 31.3334 - val_accuracy: 0.0476\n",
            "Epoch 36/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 28.6028 - accuracy: 0.9390 - val_loss: 31.2554 - val_accuracy: 0.0476\n",
            "Epoch 37/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 28.6459 - accuracy: 0.9024 - val_loss: 31.1627 - val_accuracy: 0.0476\n",
            "Epoch 38/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 28.3757 - accuracy: 0.9756 - val_loss: 31.0917 - val_accuracy: 0.0476\n",
            "Epoch 39/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 28.2843 - accuracy: 0.9390 - val_loss: 31.0359 - val_accuracy: 0.0476\n",
            "Epoch 40/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 28.1568 - accuracy: 0.9512 - val_loss: 30.9869 - val_accuracy: 0.0476\n",
            "Epoch 41/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 28.0021 - accuracy: 0.9878 - val_loss: 30.8846 - val_accuracy: 0.0476\n",
            "Epoch 42/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 27.8926 - accuracy: 0.9756 - val_loss: 30.7550 - val_accuracy: 0.0952\n",
            "Epoch 43/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 27.8120 - accuracy: 0.9878 - val_loss: 30.6126 - val_accuracy: 0.0476\n",
            "Epoch 44/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 27.6882 - accuracy: 0.9756 - val_loss: 30.4112 - val_accuracy: 0.0476\n",
            "Epoch 45/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 27.6155 - accuracy: 0.9634 - val_loss: 30.2148 - val_accuracy: 0.0952\n",
            "Epoch 46/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 27.4219 - accuracy: 0.9878 - val_loss: 30.0231 - val_accuracy: 0.0952\n",
            "Epoch 47/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 27.3103 - accuracy: 1.0000 - val_loss: 29.8595 - val_accuracy: 0.0952\n",
            "Epoch 48/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 27.2901 - accuracy: 0.9512 - val_loss: 29.7099 - val_accuracy: 0.0952\n",
            "Epoch 49/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 27.1893 - accuracy: 0.9512 - val_loss: 29.5702 - val_accuracy: 0.1429\n",
            "Epoch 50/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 26.9627 - accuracy: 1.0000 - val_loss: 29.4894 - val_accuracy: 0.1429\n",
            "Epoch 51/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 26.8863 - accuracy: 0.9634 - val_loss: 29.4005 - val_accuracy: 0.1429\n",
            "Epoch 52/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 26.7402 - accuracy: 0.9756 - val_loss: 29.2938 - val_accuracy: 0.1429\n",
            "Epoch 53/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 26.6726 - accuracy: 0.9634 - val_loss: 29.2402 - val_accuracy: 0.0952\n",
            "Epoch 54/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 26.5662 - accuracy: 0.9512 - val_loss: 29.0720 - val_accuracy: 0.0952\n",
            "Epoch 55/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 26.3864 - accuracy: 0.9878 - val_loss: 28.9036 - val_accuracy: 0.1429\n",
            "Epoch 56/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 26.2733 - accuracy: 0.9756 - val_loss: 28.7349 - val_accuracy: 0.1429\n",
            "Epoch 57/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 26.1702 - accuracy: 0.9756 - val_loss: 28.5862 - val_accuracy: 0.1429\n",
            "Epoch 58/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 26.0539 - accuracy: 0.9878 - val_loss: 28.4091 - val_accuracy: 0.2381\n",
            "Epoch 59/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 25.8895 - accuracy: 0.9878 - val_loss: 28.2427 - val_accuracy: 0.2857\n",
            "Epoch 60/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 25.8474 - accuracy: 0.9634 - val_loss: 28.0715 - val_accuracy: 0.2857\n",
            "Epoch 61/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 25.6708 - accuracy: 0.9756 - val_loss: 27.9061 - val_accuracy: 0.3810\n",
            "Epoch 62/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 25.5611 - accuracy: 0.9878 - val_loss: 27.7167 - val_accuracy: 0.3810\n",
            "Epoch 63/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 25.4837 - accuracy: 0.9756 - val_loss: 27.5480 - val_accuracy: 0.3810\n",
            "Epoch 64/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 25.3286 - accuracy: 0.9756 - val_loss: 27.4016 - val_accuracy: 0.3810\n",
            "Epoch 65/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 25.1605 - accuracy: 0.9878 - val_loss: 27.2446 - val_accuracy: 0.3810\n",
            "Epoch 66/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 25.0248 - accuracy: 1.0000 - val_loss: 27.0740 - val_accuracy: 0.3810\n",
            "Epoch 67/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 24.9023 - accuracy: 1.0000 - val_loss: 26.9009 - val_accuracy: 0.3810\n",
            "Epoch 68/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 24.8104 - accuracy: 0.9756 - val_loss: 26.7253 - val_accuracy: 0.4286\n",
            "Epoch 69/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 24.6699 - accuracy: 0.9878 - val_loss: 26.5686 - val_accuracy: 0.4286\n",
            "Epoch 70/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 24.5438 - accuracy: 0.9756 - val_loss: 26.4137 - val_accuracy: 0.4286\n",
            "Epoch 71/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 24.4197 - accuracy: 0.9756 - val_loss: 26.2409 - val_accuracy: 0.4286\n",
            "Epoch 72/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 24.2802 - accuracy: 1.0000 - val_loss: 26.0595 - val_accuracy: 0.4286\n",
            "Epoch 73/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 24.1368 - accuracy: 1.0000 - val_loss: 25.8786 - val_accuracy: 0.4286\n",
            "Epoch 74/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 24.0355 - accuracy: 1.0000 - val_loss: 25.7026 - val_accuracy: 0.4286\n",
            "Epoch 75/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 23.9135 - accuracy: 0.9878 - val_loss: 25.5201 - val_accuracy: 0.4286\n",
            "Epoch 76/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 23.7571 - accuracy: 1.0000 - val_loss: 25.3305 - val_accuracy: 0.4286\n",
            "Epoch 77/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 23.6310 - accuracy: 1.0000 - val_loss: 25.1472 - val_accuracy: 0.4286\n",
            "Epoch 78/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 23.5016 - accuracy: 1.0000 - val_loss: 24.9682 - val_accuracy: 0.4762\n",
            "Epoch 79/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 23.3658 - accuracy: 1.0000 - val_loss: 24.7912 - val_accuracy: 0.4762\n",
            "Epoch 80/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 23.2455 - accuracy: 0.9878 - val_loss: 24.6271 - val_accuracy: 0.4762\n",
            "Epoch 81/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 23.1096 - accuracy: 1.0000 - val_loss: 24.4598 - val_accuracy: 0.5238\n",
            "Epoch 82/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 22.9826 - accuracy: 1.0000 - val_loss: 24.2953 - val_accuracy: 0.5238\n",
            "Epoch 83/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 22.8732 - accuracy: 0.9878 - val_loss: 24.1336 - val_accuracy: 0.5238\n",
            "Epoch 84/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 22.7422 - accuracy: 0.9878 - val_loss: 23.9655 - val_accuracy: 0.5714\n",
            "Epoch 85/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 22.5815 - accuracy: 1.0000 - val_loss: 23.7974 - val_accuracy: 0.5714\n",
            "Epoch 86/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 22.4787 - accuracy: 0.9878 - val_loss: 23.6339 - val_accuracy: 0.5714\n",
            "Epoch 87/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 22.3409 - accuracy: 0.9878 - val_loss: 23.4803 - val_accuracy: 0.5714\n",
            "Epoch 88/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 22.2331 - accuracy: 0.9878 - val_loss: 23.3284 - val_accuracy: 0.5714\n",
            "Epoch 89/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 22.0921 - accuracy: 0.9878 - val_loss: 23.1799 - val_accuracy: 0.5714\n",
            "Epoch 90/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 21.9482 - accuracy: 1.0000 - val_loss: 23.0261 - val_accuracy: 0.5714\n",
            "Epoch 91/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 21.8071 - accuracy: 1.0000 - val_loss: 22.8682 - val_accuracy: 0.5714\n",
            "Epoch 92/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 21.7259 - accuracy: 0.9634 - val_loss: 22.7179 - val_accuracy: 0.5714\n",
            "Epoch 93/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 21.5434 - accuracy: 1.0000 - val_loss: 22.5716 - val_accuracy: 0.6190\n",
            "Epoch 94/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 21.4053 - accuracy: 1.0000 - val_loss: 22.4207 - val_accuracy: 0.6190\n",
            "Epoch 95/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 21.2976 - accuracy: 0.9756 - val_loss: 22.2785 - val_accuracy: 0.6190\n",
            "Epoch 96/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 21.1770 - accuracy: 0.9878 - val_loss: 22.1384 - val_accuracy: 0.6190\n",
            "Epoch 97/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 21.0118 - accuracy: 1.0000 - val_loss: 22.0013 - val_accuracy: 0.6190\n",
            "Epoch 98/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 20.8640 - accuracy: 1.0000 - val_loss: 21.8560 - val_accuracy: 0.6190\n",
            "Epoch 99/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 20.7929 - accuracy: 0.9756 - val_loss: 21.7129 - val_accuracy: 0.6190\n",
            "Epoch 100/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 20.6369 - accuracy: 0.9878 - val_loss: 21.5324 - val_accuracy: 0.6667\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 21.5324 - accuracy: 0.6667\n",
            "Epoch 1/100\n",
            "6/6 [==============================] - 3s 52ms/step - loss: 36.9777 - accuracy: 0.0976 - val_loss: 33.1776 - val_accuracy: 0.2857\n",
            "Epoch 2/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 34.1230 - accuracy: 0.3293 - val_loss: 33.1315 - val_accuracy: 0.2381\n",
            "Epoch 3/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 33.7395 - accuracy: 0.3537 - val_loss: 33.0988 - val_accuracy: 0.0476\n",
            "Epoch 4/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 32.9782 - accuracy: 0.4024 - val_loss: 33.0687 - val_accuracy: 0.0476\n",
            "Epoch 5/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 32.5696 - accuracy: 0.4634 - val_loss: 33.0414 - val_accuracy: 0.0476\n",
            "Epoch 6/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 32.3673 - accuracy: 0.5854 - val_loss: 33.0209 - val_accuracy: 0.0476\n",
            "Epoch 7/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 31.9514 - accuracy: 0.6220 - val_loss: 33.0053 - val_accuracy: 0.0476\n",
            "Epoch 8/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 31.8370 - accuracy: 0.6220 - val_loss: 33.0019 - val_accuracy: 0.0476\n",
            "Epoch 9/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 31.7473 - accuracy: 0.6707 - val_loss: 32.9845 - val_accuracy: 0.0476\n",
            "Epoch 10/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 31.3670 - accuracy: 0.7683 - val_loss: 32.9505 - val_accuracy: 0.0476\n",
            "Epoch 11/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 31.1554 - accuracy: 0.8171 - val_loss: 32.9212 - val_accuracy: 0.0476\n",
            "Epoch 12/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 31.1729 - accuracy: 0.7439 - val_loss: 32.9257 - val_accuracy: 0.0476\n",
            "Epoch 13/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 31.0496 - accuracy: 0.8049 - val_loss: 32.9424 - val_accuracy: 0.0476\n",
            "Epoch 14/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 30.7730 - accuracy: 0.8415 - val_loss: 32.8877 - val_accuracy: 0.0476\n",
            "Epoch 15/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 30.8865 - accuracy: 0.7927 - val_loss: 32.8327 - val_accuracy: 0.0476\n",
            "Epoch 16/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 30.6662 - accuracy: 0.7561 - val_loss: 32.8361 - val_accuracy: 0.0476\n",
            "Epoch 17/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 30.3813 - accuracy: 0.8780 - val_loss: 32.8304 - val_accuracy: 0.0476\n",
            "Epoch 18/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 30.3957 - accuracy: 0.8902 - val_loss: 32.8425 - val_accuracy: 0.0476\n",
            "Epoch 19/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 30.3693 - accuracy: 0.8659 - val_loss: 32.8897 - val_accuracy: 0.0476\n",
            "Epoch 20/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 30.1489 - accuracy: 0.8659 - val_loss: 32.8524 - val_accuracy: 0.0476\n",
            "Epoch 21/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 29.9482 - accuracy: 0.9268 - val_loss: 32.8418 - val_accuracy: 0.0476\n",
            "Epoch 22/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 29.8221 - accuracy: 0.9146 - val_loss: 32.7794 - val_accuracy: 0.0476\n",
            "Epoch 23/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 29.6773 - accuracy: 0.9512 - val_loss: 32.6877 - val_accuracy: 0.0476\n",
            "Epoch 24/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 29.6740 - accuracy: 0.9146 - val_loss: 32.5939 - val_accuracy: 0.0476\n",
            "Epoch 25/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 29.5423 - accuracy: 0.9146 - val_loss: 32.4793 - val_accuracy: 0.0476\n",
            "Epoch 26/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 29.4219 - accuracy: 0.9512 - val_loss: 32.3550 - val_accuracy: 0.0476\n",
            "Epoch 27/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 29.4310 - accuracy: 0.9024 - val_loss: 32.2067 - val_accuracy: 0.0476\n",
            "Epoch 28/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 29.2276 - accuracy: 0.8902 - val_loss: 32.0567 - val_accuracy: 0.0476\n",
            "Epoch 29/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 29.1898 - accuracy: 0.9268 - val_loss: 31.9727 - val_accuracy: 0.0476\n",
            "Epoch 30/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 29.0065 - accuracy: 0.9268 - val_loss: 31.9719 - val_accuracy: 0.0476\n",
            "Epoch 31/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 28.8075 - accuracy: 0.9756 - val_loss: 31.9329 - val_accuracy: 0.0476\n",
            "Epoch 32/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 28.8288 - accuracy: 0.9268 - val_loss: 31.8904 - val_accuracy: 0.0476\n",
            "Epoch 33/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 28.7910 - accuracy: 0.9390 - val_loss: 31.8244 - val_accuracy: 0.0476\n",
            "Epoch 34/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 28.5447 - accuracy: 0.9756 - val_loss: 31.7434 - val_accuracy: 0.0476\n",
            "Epoch 35/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 28.3777 - accuracy: 0.9878 - val_loss: 31.6313 - val_accuracy: 0.0476\n",
            "Epoch 36/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 28.3203 - accuracy: 0.9756 - val_loss: 31.5179 - val_accuracy: 0.0476\n",
            "Epoch 37/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 28.2259 - accuracy: 0.9756 - val_loss: 31.4027 - val_accuracy: 0.0476\n",
            "Epoch 38/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 28.1643 - accuracy: 0.9390 - val_loss: 31.2009 - val_accuracy: 0.0952\n",
            "Epoch 39/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 27.9842 - accuracy: 0.9878 - val_loss: 31.0090 - val_accuracy: 0.0952\n",
            "Epoch 40/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 27.9325 - accuracy: 0.9512 - val_loss: 30.8325 - val_accuracy: 0.1429\n",
            "Epoch 41/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 27.7476 - accuracy: 0.9756 - val_loss: 30.6637 - val_accuracy: 0.1429\n",
            "Epoch 42/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 27.6057 - accuracy: 0.9878 - val_loss: 30.5077 - val_accuracy: 0.1429\n",
            "Epoch 43/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 27.5084 - accuracy: 0.9756 - val_loss: 30.3784 - val_accuracy: 0.1429\n",
            "Epoch 44/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 27.4148 - accuracy: 0.9634 - val_loss: 30.2346 - val_accuracy: 0.1429\n",
            "Epoch 45/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 27.2932 - accuracy: 0.9756 - val_loss: 30.0694 - val_accuracy: 0.1429\n",
            "Epoch 46/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 27.1545 - accuracy: 0.9878 - val_loss: 29.9024 - val_accuracy: 0.1905\n",
            "Epoch 47/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 27.0809 - accuracy: 0.9756 - val_loss: 29.7666 - val_accuracy: 0.1905\n",
            "Epoch 48/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 26.9047 - accuracy: 1.0000 - val_loss: 29.7662 - val_accuracy: 0.1429\n",
            "Epoch 49/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 26.9169 - accuracy: 0.9146 - val_loss: 29.5845 - val_accuracy: 0.2381\n",
            "Epoch 50/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 26.7682 - accuracy: 0.9634 - val_loss: 29.3603 - val_accuracy: 0.2381\n",
            "Epoch 51/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 26.6096 - accuracy: 0.9756 - val_loss: 29.1616 - val_accuracy: 0.2381\n",
            "Epoch 52/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 26.4390 - accuracy: 0.9878 - val_loss: 28.9604 - val_accuracy: 0.2381\n",
            "Epoch 53/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 26.3545 - accuracy: 0.9756 - val_loss: 28.7752 - val_accuracy: 0.2381\n",
            "Epoch 54/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 26.2742 - accuracy: 0.9634 - val_loss: 28.6006 - val_accuracy: 0.1905\n",
            "Epoch 55/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 26.1014 - accuracy: 0.9878 - val_loss: 28.4367 - val_accuracy: 0.1905\n",
            "Epoch 56/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 25.9871 - accuracy: 0.9756 - val_loss: 28.2975 - val_accuracy: 0.1905\n",
            "Epoch 57/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 25.8854 - accuracy: 0.9634 - val_loss: 28.2094 - val_accuracy: 0.2381\n",
            "Epoch 58/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 25.6933 - accuracy: 1.0000 - val_loss: 28.0769 - val_accuracy: 0.2381\n",
            "Epoch 59/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 25.5794 - accuracy: 0.9878 - val_loss: 27.8992 - val_accuracy: 0.2381\n",
            "Epoch 60/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 25.4849 - accuracy: 0.9756 - val_loss: 27.6915 - val_accuracy: 0.2857\n",
            "Epoch 61/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 25.3645 - accuracy: 0.9756 - val_loss: 27.5018 - val_accuracy: 0.2857\n",
            "Epoch 62/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 25.2018 - accuracy: 1.0000 - val_loss: 27.3333 - val_accuracy: 0.3333\n",
            "Epoch 63/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 25.0662 - accuracy: 1.0000 - val_loss: 27.1627 - val_accuracy: 0.3333\n",
            "Epoch 64/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 24.9309 - accuracy: 1.0000 - val_loss: 26.9920 - val_accuracy: 0.3333\n",
            "Epoch 65/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 24.8237 - accuracy: 1.0000 - val_loss: 26.8103 - val_accuracy: 0.3333\n",
            "Epoch 66/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 24.7244 - accuracy: 0.9878 - val_loss: 26.6758 - val_accuracy: 0.3333\n",
            "Epoch 67/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 24.5649 - accuracy: 1.0000 - val_loss: 26.5226 - val_accuracy: 0.3333\n",
            "Epoch 68/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 24.4430 - accuracy: 0.9878 - val_loss: 26.3608 - val_accuracy: 0.3810\n",
            "Epoch 69/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 24.3203 - accuracy: 0.9878 - val_loss: 26.1899 - val_accuracy: 0.3810\n",
            "Epoch 70/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 24.1855 - accuracy: 0.9878 - val_loss: 26.0123 - val_accuracy: 0.4286\n",
            "Epoch 71/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 24.0453 - accuracy: 0.9878 - val_loss: 25.8412 - val_accuracy: 0.4762\n",
            "Epoch 72/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 23.9209 - accuracy: 1.0000 - val_loss: 25.6675 - val_accuracy: 0.4762\n",
            "Epoch 73/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 23.7797 - accuracy: 1.0000 - val_loss: 25.4900 - val_accuracy: 0.4762\n",
            "Epoch 74/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 23.6952 - accuracy: 0.9878 - val_loss: 25.3126 - val_accuracy: 0.4762\n",
            "Epoch 75/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 23.5355 - accuracy: 1.0000 - val_loss: 25.1235 - val_accuracy: 0.4762\n",
            "Epoch 76/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 23.3881 - accuracy: 1.0000 - val_loss: 24.9367 - val_accuracy: 0.6190\n",
            "Epoch 77/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 23.2633 - accuracy: 1.0000 - val_loss: 24.7589 - val_accuracy: 0.6190\n",
            "Epoch 78/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 23.1256 - accuracy: 1.0000 - val_loss: 24.5925 - val_accuracy: 0.6190\n",
            "Epoch 79/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 23.0211 - accuracy: 0.9878 - val_loss: 24.4161 - val_accuracy: 0.6190\n",
            "Epoch 80/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 22.8647 - accuracy: 1.0000 - val_loss: 24.2455 - val_accuracy: 0.5714\n",
            "Epoch 81/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 22.7233 - accuracy: 1.0000 - val_loss: 24.0791 - val_accuracy: 0.5714\n",
            "Epoch 82/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 22.6119 - accuracy: 0.9878 - val_loss: 23.9219 - val_accuracy: 0.6190\n",
            "Epoch 83/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 22.4667 - accuracy: 1.0000 - val_loss: 23.7681 - val_accuracy: 0.6190\n",
            "Epoch 84/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 22.3369 - accuracy: 0.9878 - val_loss: 23.6134 - val_accuracy: 0.6190\n",
            "Epoch 85/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 22.2009 - accuracy: 1.0000 - val_loss: 23.4564 - val_accuracy: 0.6190\n",
            "Epoch 86/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 22.0740 - accuracy: 0.9878 - val_loss: 23.3042 - val_accuracy: 0.6190\n",
            "Epoch 87/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 21.9257 - accuracy: 1.0000 - val_loss: 23.1507 - val_accuracy: 0.6190\n",
            "Epoch 88/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 21.8131 - accuracy: 0.9878 - val_loss: 22.9803 - val_accuracy: 0.6190\n",
            "Epoch 89/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 21.6531 - accuracy: 1.0000 - val_loss: 22.8129 - val_accuracy: 0.6190\n",
            "Epoch 90/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 21.5149 - accuracy: 1.0000 - val_loss: 22.6518 - val_accuracy: 0.6190\n",
            "Epoch 91/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 21.3962 - accuracy: 0.9878 - val_loss: 22.4947 - val_accuracy: 0.6190\n",
            "Epoch 92/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 21.2512 - accuracy: 1.0000 - val_loss: 22.3401 - val_accuracy: 0.6190\n",
            "Epoch 93/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 21.1533 - accuracy: 0.9756 - val_loss: 22.1635 - val_accuracy: 0.6190\n",
            "Epoch 94/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 20.9824 - accuracy: 1.0000 - val_loss: 21.9993 - val_accuracy: 0.6190\n",
            "Epoch 95/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 20.8669 - accuracy: 0.9878 - val_loss: 21.8604 - val_accuracy: 0.6190\n",
            "Epoch 96/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 20.7109 - accuracy: 1.0000 - val_loss: 21.7171 - val_accuracy: 0.6190\n",
            "Epoch 97/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 20.5982 - accuracy: 0.9878 - val_loss: 21.5775 - val_accuracy: 0.6190\n",
            "Epoch 98/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 20.4718 - accuracy: 0.9878 - val_loss: 21.4618 - val_accuracy: 0.6190\n",
            "Epoch 99/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 20.3020 - accuracy: 1.0000 - val_loss: 21.3371 - val_accuracy: 0.6190\n",
            "Epoch 100/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 20.1687 - accuracy: 1.0000 - val_loss: 21.2006 - val_accuracy: 0.6190\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 21.2006 - accuracy: 0.6190\n",
            "Epoch 1/100\n",
            "6/6 [==============================] - 3s 142ms/step - loss: 37.1220 - accuracy: 0.1084 - val_loss: 33.4402 - val_accuracy: 0.1000\n",
            "Epoch 2/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 34.7699 - accuracy: 0.1928 - val_loss: 33.4033 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 33.8207 - accuracy: 0.3012 - val_loss: 33.4151 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 33.8104 - accuracy: 0.3614 - val_loss: 33.4595 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 33.2467 - accuracy: 0.4458 - val_loss: 33.5018 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/100\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 33.0530 - accuracy: 0.4458 - val_loss: 33.4972 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/100\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 32.7837 - accuracy: 0.5301 - val_loss: 33.4880 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/100\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 32.0958 - accuracy: 0.6988 - val_loss: 33.4770 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/100\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 31.8001 - accuracy: 0.7470 - val_loss: 33.4792 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/100\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 31.6272 - accuracy: 0.7470 - val_loss: 33.4911 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/100\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 31.4877 - accuracy: 0.8193 - val_loss: 33.5027 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/100\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 31.5949 - accuracy: 0.6867 - val_loss: 33.5152 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/100\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 31.0994 - accuracy: 0.8675 - val_loss: 33.5224 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/100\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 30.9844 - accuracy: 0.8675 - val_loss: 33.5050 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/100\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 31.1166 - accuracy: 0.7952 - val_loss: 33.4873 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 30.7027 - accuracy: 0.8916 - val_loss: 33.4521 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 30.8222 - accuracy: 0.8434 - val_loss: 33.4034 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 30.6762 - accuracy: 0.8434 - val_loss: 33.3494 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 30.3535 - accuracy: 0.9398 - val_loss: 33.3044 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 30.2401 - accuracy: 0.9518 - val_loss: 33.2578 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 30.1432 - accuracy: 0.9639 - val_loss: 33.2083 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/100\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 30.1136 - accuracy: 0.9639 - val_loss: 33.1321 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/100\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 29.9527 - accuracy: 0.9639 - val_loss: 33.0576 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/100\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 29.8630 - accuracy: 0.9518 - val_loss: 32.9793 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 29.8483 - accuracy: 0.9157 - val_loss: 32.9014 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 29.7457 - accuracy: 0.9518 - val_loss: 32.8236 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 29.5097 - accuracy: 0.9759 - val_loss: 32.7321 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 29.5585 - accuracy: 0.9277 - val_loss: 32.6845 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 29.4136 - accuracy: 0.9277 - val_loss: 32.6270 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 29.2364 - accuracy: 0.9759 - val_loss: 32.5845 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/100\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 29.2836 - accuracy: 0.9036 - val_loss: 32.4956 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 28.9914 - accuracy: 0.9880 - val_loss: 32.3589 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 28.9323 - accuracy: 0.9639 - val_loss: 32.1845 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 28.8574 - accuracy: 0.9398 - val_loss: 32.0287 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 28.6747 - accuracy: 1.0000 - val_loss: 31.9989 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 28.6246 - accuracy: 0.9518 - val_loss: 31.8872 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 28.5104 - accuracy: 0.9880 - val_loss: 31.7430 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 28.3620 - accuracy: 1.0000 - val_loss: 31.6161 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 28.3110 - accuracy: 0.9759 - val_loss: 31.4760 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 28.1508 - accuracy: 0.9639 - val_loss: 31.3106 - val_accuracy: 0.0500\n",
            "Epoch 41/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 28.0057 - accuracy: 1.0000 - val_loss: 31.1532 - val_accuracy: 0.0500\n",
            "Epoch 42/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 27.9291 - accuracy: 0.9759 - val_loss: 30.9894 - val_accuracy: 0.0500\n",
            "Epoch 43/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 27.8126 - accuracy: 0.9880 - val_loss: 30.8212 - val_accuracy: 0.1000\n",
            "Epoch 44/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 27.8177 - accuracy: 0.9398 - val_loss: 30.6386 - val_accuracy: 0.1000\n",
            "Epoch 45/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 27.5641 - accuracy: 1.0000 - val_loss: 30.4777 - val_accuracy: 0.1000\n",
            "Epoch 46/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 27.4886 - accuracy: 0.9759 - val_loss: 30.3744 - val_accuracy: 0.1000\n",
            "Epoch 47/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 27.3801 - accuracy: 0.9880 - val_loss: 30.2497 - val_accuracy: 0.1000\n",
            "Epoch 48/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 27.3140 - accuracy: 0.9398 - val_loss: 30.1406 - val_accuracy: 0.1000\n",
            "Epoch 49/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 27.1534 - accuracy: 0.9759 - val_loss: 30.0025 - val_accuracy: 0.1000\n",
            "Epoch 50/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 27.0097 - accuracy: 0.9880 - val_loss: 29.8465 - val_accuracy: 0.1000\n",
            "Epoch 51/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 26.9365 - accuracy: 0.9639 - val_loss: 29.6443 - val_accuracy: 0.1000\n",
            "Epoch 52/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 26.8032 - accuracy: 0.9639 - val_loss: 29.4221 - val_accuracy: 0.1000\n",
            "Epoch 53/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 26.6397 - accuracy: 0.9880 - val_loss: 29.2269 - val_accuracy: 0.1000\n",
            "Epoch 54/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 26.5819 - accuracy: 0.9759 - val_loss: 29.0332 - val_accuracy: 0.1000\n",
            "Epoch 55/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 26.4235 - accuracy: 0.9759 - val_loss: 28.8629 - val_accuracy: 0.1000\n",
            "Epoch 56/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 26.3235 - accuracy: 0.9759 - val_loss: 28.7002 - val_accuracy: 0.1000\n",
            "Epoch 57/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 26.1764 - accuracy: 0.9759 - val_loss: 28.5241 - val_accuracy: 0.1500\n",
            "Epoch 58/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 26.0518 - accuracy: 0.9759 - val_loss: 28.3784 - val_accuracy: 0.1500\n",
            "Epoch 59/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 25.9100 - accuracy: 0.9880 - val_loss: 28.2483 - val_accuracy: 0.2000\n",
            "Epoch 60/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 25.7723 - accuracy: 1.0000 - val_loss: 28.1056 - val_accuracy: 0.2500\n",
            "Epoch 61/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 25.6648 - accuracy: 1.0000 - val_loss: 27.9489 - val_accuracy: 0.2500\n",
            "Epoch 62/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 25.5788 - accuracy: 0.9639 - val_loss: 27.7810 - val_accuracy: 0.2500\n",
            "Epoch 63/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 25.4045 - accuracy: 1.0000 - val_loss: 27.6058 - val_accuracy: 0.2500\n",
            "Epoch 64/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 25.3123 - accuracy: 0.9759 - val_loss: 27.4680 - val_accuracy: 0.2500\n",
            "Epoch 65/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 25.2118 - accuracy: 0.9880 - val_loss: 27.3338 - val_accuracy: 0.2500\n",
            "Epoch 66/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 25.0794 - accuracy: 0.9639 - val_loss: 27.1875 - val_accuracy: 0.2500\n",
            "Epoch 67/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 24.8912 - accuracy: 1.0000 - val_loss: 27.0446 - val_accuracy: 0.2500\n",
            "Epoch 68/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 24.7730 - accuracy: 1.0000 - val_loss: 26.8922 - val_accuracy: 0.2500\n",
            "Epoch 69/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 24.6686 - accuracy: 0.9639 - val_loss: 26.7164 - val_accuracy: 0.2500\n",
            "Epoch 70/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 24.5838 - accuracy: 0.9759 - val_loss: 26.5496 - val_accuracy: 0.2500\n",
            "Epoch 71/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 24.4380 - accuracy: 0.9880 - val_loss: 26.3952 - val_accuracy: 0.2500\n",
            "Epoch 72/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 24.2577 - accuracy: 1.0000 - val_loss: 26.2488 - val_accuracy: 0.2500\n",
            "Epoch 73/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 24.1654 - accuracy: 0.9880 - val_loss: 26.0905 - val_accuracy: 0.3000\n",
            "Epoch 74/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 24.0196 - accuracy: 0.9880 - val_loss: 25.9316 - val_accuracy: 0.3000\n",
            "Epoch 75/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 23.8827 - accuracy: 0.9880 - val_loss: 25.7843 - val_accuracy: 0.3000\n",
            "Epoch 76/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 23.7996 - accuracy: 0.9759 - val_loss: 25.6541 - val_accuracy: 0.3000\n",
            "Epoch 77/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 23.6120 - accuracy: 0.9880 - val_loss: 25.5146 - val_accuracy: 0.3000\n",
            "Epoch 78/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 23.5334 - accuracy: 0.9759 - val_loss: 25.3536 - val_accuracy: 0.3000\n",
            "Epoch 79/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 23.4167 - accuracy: 0.9759 - val_loss: 25.1633 - val_accuracy: 0.3000\n",
            "Epoch 80/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 23.2108 - accuracy: 1.0000 - val_loss: 24.9850 - val_accuracy: 0.3500\n",
            "Epoch 81/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 23.0775 - accuracy: 1.0000 - val_loss: 24.8181 - val_accuracy: 0.3500\n",
            "Epoch 82/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 22.9665 - accuracy: 0.9880 - val_loss: 24.6526 - val_accuracy: 0.3500\n",
            "Epoch 83/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 22.8379 - accuracy: 1.0000 - val_loss: 24.4827 - val_accuracy: 0.4000\n",
            "Epoch 84/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 22.6854 - accuracy: 1.0000 - val_loss: 24.3110 - val_accuracy: 0.4000\n",
            "Epoch 85/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 22.5653 - accuracy: 1.0000 - val_loss: 24.1400 - val_accuracy: 0.5000\n",
            "Epoch 86/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 22.4246 - accuracy: 1.0000 - val_loss: 23.9739 - val_accuracy: 0.5500\n",
            "Epoch 87/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 22.2917 - accuracy: 1.0000 - val_loss: 23.8097 - val_accuracy: 0.5500\n",
            "Epoch 88/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 22.1517 - accuracy: 1.0000 - val_loss: 23.6525 - val_accuracy: 0.5500\n",
            "Epoch 89/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 22.0313 - accuracy: 1.0000 - val_loss: 23.4957 - val_accuracy: 0.5000\n",
            "Epoch 90/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 21.9044 - accuracy: 0.9880 - val_loss: 23.3387 - val_accuracy: 0.5000\n",
            "Epoch 91/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 21.7518 - accuracy: 1.0000 - val_loss: 23.1851 - val_accuracy: 0.5000\n",
            "Epoch 92/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 21.6289 - accuracy: 0.9880 - val_loss: 23.0387 - val_accuracy: 0.5500\n",
            "Epoch 93/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 21.4849 - accuracy: 1.0000 - val_loss: 22.8930 - val_accuracy: 0.5000\n",
            "Epoch 94/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 21.3803 - accuracy: 0.9880 - val_loss: 22.7434 - val_accuracy: 0.5000\n",
            "Epoch 95/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 21.2205 - accuracy: 1.0000 - val_loss: 22.5855 - val_accuracy: 0.5500\n",
            "Epoch 96/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 21.1060 - accuracy: 0.9880 - val_loss: 22.4248 - val_accuracy: 0.5500\n",
            "Epoch 97/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 20.9623 - accuracy: 0.9880 - val_loss: 22.2685 - val_accuracy: 0.5500\n",
            "Epoch 98/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 20.8141 - accuracy: 1.0000 - val_loss: 22.1166 - val_accuracy: 0.5500\n",
            "Epoch 99/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 20.6999 - accuracy: 0.9880 - val_loss: 21.9598 - val_accuracy: 0.5500\n",
            "Epoch 100/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 20.5690 - accuracy: 0.9880 - val_loss: 21.8018 - val_accuracy: 0.5500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 21.8018 - accuracy: 0.5500\n",
            "Epoch 1/100\n",
            "6/6 [==============================] - 3s 50ms/step - loss: 37.7675 - accuracy: 0.0241 - val_loss: 33.3647 - val_accuracy: 0.3500\n",
            "Epoch 2/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 34.3275 - accuracy: 0.3735 - val_loss: 33.3058 - val_accuracy: 0.1000\n",
            "Epoch 3/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 34.2832 - accuracy: 0.3012 - val_loss: 33.2463 - val_accuracy: 0.1000\n",
            "Epoch 4/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 33.4867 - accuracy: 0.3494 - val_loss: 33.2024 - val_accuracy: 0.1000\n",
            "Epoch 5/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 33.3470 - accuracy: 0.4217 - val_loss: 33.1614 - val_accuracy: 0.1000\n",
            "Epoch 6/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 32.3912 - accuracy: 0.5904 - val_loss: 33.1225 - val_accuracy: 0.1000\n",
            "Epoch 7/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 32.1922 - accuracy: 0.6145 - val_loss: 33.0904 - val_accuracy: 0.1000\n",
            "Epoch 8/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 32.1429 - accuracy: 0.5663 - val_loss: 33.0659 - val_accuracy: 0.1000\n",
            "Epoch 9/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 31.8976 - accuracy: 0.6627 - val_loss: 33.0530 - val_accuracy: 0.1000\n",
            "Epoch 10/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 31.5886 - accuracy: 0.6867 - val_loss: 33.0315 - val_accuracy: 0.1000\n",
            "Epoch 11/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 31.4865 - accuracy: 0.7470 - val_loss: 33.0338 - val_accuracy: 0.1000\n",
            "Epoch 12/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 31.4532 - accuracy: 0.7349 - val_loss: 33.0651 - val_accuracy: 0.1000\n",
            "Epoch 13/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 31.0667 - accuracy: 0.8193 - val_loss: 33.1208 - val_accuracy: 0.1000\n",
            "Epoch 14/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 31.0226 - accuracy: 0.8313 - val_loss: 33.1611 - val_accuracy: 0.1000\n",
            "Epoch 15/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 30.9740 - accuracy: 0.8193 - val_loss: 33.1785 - val_accuracy: 0.1000\n",
            "Epoch 16/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 30.8263 - accuracy: 0.7831 - val_loss: 33.1570 - val_accuracy: 0.1000\n",
            "Epoch 17/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 30.5508 - accuracy: 0.8916 - val_loss: 33.1214 - val_accuracy: 0.1000\n",
            "Epoch 18/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 30.5687 - accuracy: 0.8916 - val_loss: 33.1104 - val_accuracy: 0.1000\n",
            "Epoch 19/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 30.4222 - accuracy: 0.9157 - val_loss: 33.0815 - val_accuracy: 0.1000\n",
            "Epoch 20/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 30.4084 - accuracy: 0.8434 - val_loss: 33.0644 - val_accuracy: 0.1000\n",
            "Epoch 21/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 30.1263 - accuracy: 0.9277 - val_loss: 33.0246 - val_accuracy: 0.1000\n",
            "Epoch 22/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 30.0049 - accuracy: 0.9518 - val_loss: 33.0219 - val_accuracy: 0.1000\n",
            "Epoch 23/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 29.9384 - accuracy: 0.9036 - val_loss: 33.0266 - val_accuracy: 0.1000\n",
            "Epoch 24/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 29.9878 - accuracy: 0.8675 - val_loss: 33.0134 - val_accuracy: 0.1000\n",
            "Epoch 25/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 29.7784 - accuracy: 0.9036 - val_loss: 32.9955 - val_accuracy: 0.1000\n",
            "Epoch 26/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 29.6457 - accuracy: 0.9398 - val_loss: 32.9268 - val_accuracy: 0.1000\n",
            "Epoch 27/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 29.5423 - accuracy: 0.9518 - val_loss: 32.8430 - val_accuracy: 0.1000\n",
            "Epoch 28/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 29.4223 - accuracy: 0.9398 - val_loss: 32.7247 - val_accuracy: 0.1000\n",
            "Epoch 29/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 29.3137 - accuracy: 0.9398 - val_loss: 32.6024 - val_accuracy: 0.1000\n",
            "Epoch 30/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 29.2031 - accuracy: 0.9518 - val_loss: 32.4836 - val_accuracy: 0.1000\n",
            "Epoch 31/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 29.1139 - accuracy: 0.9398 - val_loss: 32.3867 - val_accuracy: 0.1000\n",
            "Epoch 32/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 28.9625 - accuracy: 0.9639 - val_loss: 32.2987 - val_accuracy: 0.1000\n",
            "Epoch 33/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 28.8439 - accuracy: 0.9759 - val_loss: 32.2332 - val_accuracy: 0.1000\n",
            "Epoch 34/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 28.7568 - accuracy: 0.9398 - val_loss: 32.1855 - val_accuracy: 0.1000\n",
            "Epoch 35/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 28.5868 - accuracy: 1.0000 - val_loss: 32.1611 - val_accuracy: 0.1000\n",
            "Epoch 36/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 28.5561 - accuracy: 0.9518 - val_loss: 32.0758 - val_accuracy: 0.1000\n",
            "Epoch 37/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 28.4397 - accuracy: 0.9639 - val_loss: 31.9703 - val_accuracy: 0.1000\n",
            "Epoch 38/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 28.2956 - accuracy: 0.9759 - val_loss: 31.9291 - val_accuracy: 0.1000\n",
            "Epoch 39/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 28.2141 - accuracy: 0.9759 - val_loss: 31.8707 - val_accuracy: 0.1000\n",
            "Epoch 40/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 28.1204 - accuracy: 0.9518 - val_loss: 31.7512 - val_accuracy: 0.1000\n",
            "Epoch 41/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 27.9333 - accuracy: 0.9880 - val_loss: 31.5869 - val_accuracy: 0.1000\n",
            "Epoch 42/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 27.7994 - accuracy: 1.0000 - val_loss: 31.4328 - val_accuracy: 0.1000\n",
            "Epoch 43/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 27.6892 - accuracy: 1.0000 - val_loss: 31.2745 - val_accuracy: 0.1000\n",
            "Epoch 44/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 27.6338 - accuracy: 0.9398 - val_loss: 31.0766 - val_accuracy: 0.1000\n",
            "Epoch 45/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 27.5336 - accuracy: 0.9759 - val_loss: 30.9060 - val_accuracy: 0.1000\n",
            "Epoch 46/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 27.3667 - accuracy: 0.9759 - val_loss: 30.7785 - val_accuracy: 0.1000\n",
            "Epoch 47/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 27.2306 - accuracy: 0.9880 - val_loss: 30.6475 - val_accuracy: 0.1000\n",
            "Epoch 48/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 27.1828 - accuracy: 0.9639 - val_loss: 30.4812 - val_accuracy: 0.1000\n",
            "Epoch 49/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 27.0306 - accuracy: 0.9759 - val_loss: 30.3377 - val_accuracy: 0.1000\n",
            "Epoch 50/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 26.8486 - accuracy: 1.0000 - val_loss: 30.1884 - val_accuracy: 0.1000\n",
            "Epoch 51/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 26.7445 - accuracy: 1.0000 - val_loss: 30.0179 - val_accuracy: 0.1000\n",
            "Epoch 52/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 26.6439 - accuracy: 0.9759 - val_loss: 29.8553 - val_accuracy: 0.1000\n",
            "Epoch 53/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 26.5442 - accuracy: 0.9759 - val_loss: 29.6825 - val_accuracy: 0.1000\n",
            "Epoch 54/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 26.4584 - accuracy: 0.9518 - val_loss: 29.5205 - val_accuracy: 0.1000\n",
            "Epoch 55/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 26.2640 - accuracy: 0.9880 - val_loss: 29.3298 - val_accuracy: 0.1000\n",
            "Epoch 56/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 26.1294 - accuracy: 1.0000 - val_loss: 29.1455 - val_accuracy: 0.1000\n",
            "Epoch 57/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 26.0433 - accuracy: 0.9880 - val_loss: 28.9614 - val_accuracy: 0.1000\n",
            "Epoch 58/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 25.8933 - accuracy: 0.9880 - val_loss: 28.7773 - val_accuracy: 0.1000\n",
            "Epoch 59/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 25.7708 - accuracy: 1.0000 - val_loss: 28.6052 - val_accuracy: 0.1500\n",
            "Epoch 60/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 25.6396 - accuracy: 0.9880 - val_loss: 28.4110 - val_accuracy: 0.2000\n",
            "Epoch 61/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 25.5336 - accuracy: 1.0000 - val_loss: 28.2440 - val_accuracy: 0.2500\n",
            "Epoch 62/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 25.5105 - accuracy: 0.9398 - val_loss: 28.0307 - val_accuracy: 0.2500\n",
            "Epoch 63/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 25.2566 - accuracy: 0.9880 - val_loss: 27.8225 - val_accuracy: 0.3000\n",
            "Epoch 64/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 25.1582 - accuracy: 0.9759 - val_loss: 27.6206 - val_accuracy: 0.3500\n",
            "Epoch 65/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 24.9896 - accuracy: 1.0000 - val_loss: 27.4348 - val_accuracy: 0.3500\n",
            "Epoch 66/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 24.8668 - accuracy: 1.0000 - val_loss: 27.2436 - val_accuracy: 0.3500\n",
            "Epoch 67/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 24.7568 - accuracy: 0.9880 - val_loss: 27.0506 - val_accuracy: 0.4000\n",
            "Epoch 68/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 24.6515 - accuracy: 0.9639 - val_loss: 26.8520 - val_accuracy: 0.3500\n",
            "Epoch 69/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 24.4912 - accuracy: 0.9759 - val_loss: 26.6542 - val_accuracy: 0.4000\n",
            "Epoch 70/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 24.3289 - accuracy: 1.0000 - val_loss: 26.4685 - val_accuracy: 0.4000\n",
            "Epoch 71/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 24.2447 - accuracy: 0.9880 - val_loss: 26.2818 - val_accuracy: 0.4000\n",
            "Epoch 72/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 24.1028 - accuracy: 0.9880 - val_loss: 26.1099 - val_accuracy: 0.4000\n",
            "Epoch 73/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 23.9542 - accuracy: 1.0000 - val_loss: 25.9228 - val_accuracy: 0.4000\n",
            "Epoch 74/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 23.8312 - accuracy: 0.9880 - val_loss: 25.7576 - val_accuracy: 0.4000\n",
            "Epoch 75/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 23.6968 - accuracy: 1.0000 - val_loss: 25.5949 - val_accuracy: 0.4000\n",
            "Epoch 76/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 23.5508 - accuracy: 1.0000 - val_loss: 25.4256 - val_accuracy: 0.4000\n",
            "Epoch 77/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 23.4171 - accuracy: 1.0000 - val_loss: 25.2532 - val_accuracy: 0.4000\n",
            "Epoch 78/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 23.2868 - accuracy: 1.0000 - val_loss: 25.0701 - val_accuracy: 0.4000\n",
            "Epoch 79/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 23.1514 - accuracy: 1.0000 - val_loss: 24.8820 - val_accuracy: 0.4500\n",
            "Epoch 80/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 23.0123 - accuracy: 1.0000 - val_loss: 24.6971 - val_accuracy: 0.4500\n",
            "Epoch 81/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 22.8874 - accuracy: 1.0000 - val_loss: 24.5214 - val_accuracy: 0.4500\n",
            "Epoch 82/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 22.7679 - accuracy: 0.9759 - val_loss: 24.3322 - val_accuracy: 0.4500\n",
            "Epoch 83/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 22.6570 - accuracy: 0.9880 - val_loss: 24.1342 - val_accuracy: 0.4500\n",
            "Epoch 84/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 22.4872 - accuracy: 1.0000 - val_loss: 23.9505 - val_accuracy: 0.4500\n",
            "Epoch 85/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 22.3531 - accuracy: 1.0000 - val_loss: 23.7631 - val_accuracy: 0.4500\n",
            "Epoch 86/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 22.2413 - accuracy: 0.9880 - val_loss: 23.5909 - val_accuracy: 0.4500\n",
            "Epoch 87/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 22.1052 - accuracy: 0.9759 - val_loss: 23.4162 - val_accuracy: 0.5000\n",
            "Epoch 88/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 21.9730 - accuracy: 0.9759 - val_loss: 23.2387 - val_accuracy: 0.5000\n",
            "Epoch 89/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 21.8556 - accuracy: 0.9880 - val_loss: 23.0699 - val_accuracy: 0.5000\n",
            "Epoch 90/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 21.6777 - accuracy: 1.0000 - val_loss: 22.8973 - val_accuracy: 0.5000\n",
            "Epoch 91/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 21.5560 - accuracy: 0.9880 - val_loss: 22.7321 - val_accuracy: 0.5500\n",
            "Epoch 92/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 21.4192 - accuracy: 0.9880 - val_loss: 22.5657 - val_accuracy: 0.5500\n",
            "Epoch 93/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 21.2688 - accuracy: 1.0000 - val_loss: 22.4092 - val_accuracy: 0.6000\n",
            "Epoch 94/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 21.1524 - accuracy: 0.9880 - val_loss: 22.2505 - val_accuracy: 0.6500\n",
            "Epoch 95/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 21.0095 - accuracy: 1.0000 - val_loss: 22.0934 - val_accuracy: 0.6500\n",
            "Epoch 96/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 20.9022 - accuracy: 0.9880 - val_loss: 21.9414 - val_accuracy: 0.6500\n",
            "Epoch 97/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 20.7679 - accuracy: 0.9759 - val_loss: 21.7917 - val_accuracy: 0.6500\n",
            "Epoch 98/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 20.6191 - accuracy: 0.9880 - val_loss: 21.6409 - val_accuracy: 0.6500\n",
            "Epoch 99/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 20.4771 - accuracy: 0.9880 - val_loss: 21.4769 - val_accuracy: 0.7000\n",
            "Epoch 100/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 20.3310 - accuracy: 1.0000 - val_loss: 21.3187 - val_accuracy: 0.7000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 21.3187 - accuracy: 0.7000\n",
            "------------------------------------------------------------------------\n",
            "Score per fold\n",
            "> Fold 1 - Loss: 21.9678955078125 - Accuracy: 33.33333432674408%\n",
            "> Fold 2 - Loss: 21.53240203857422 - Accuracy: 66.66666865348816%\n",
            "> Fold 3 - Loss: 21.200557708740234 - Accuracy: 61.90476417541504%\n",
            "> Fold 4 - Loss: 21.801847457885742 - Accuracy: 55.000001192092896%\n",
            "> Fold 5 - Loss: 21.31868553161621 - Accuracy: 69.9999988079071%\n",
            "------------------------------------------------------------------------\n",
            "Average scores for all folds:\n",
            "> Accuracy: 57.380953431129456 (+- 13.037535006405196)\n",
            "> Loss: 21.56427764892578\n",
            "------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Advance Technique to Increase Accuracy"
      ],
      "metadata": {
        "id": "CKWhsqfTiIlt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "import math\n",
        "\n",
        "# Function to adjust the learning rate\n",
        "def step_decay(epoch):\n",
        "    initial_lrate = 0.001\n",
        "    drop = 0.5\n",
        "    epochs_drop = 10.0\n",
        "    lrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
        "    return lrate\n",
        "\n",
        "lrate = LearningRateScheduler(step_decay)\n",
        "\n",
        "# Re-compiling the model with an adjusted optimizer\n",
        "model.compile(optimizer=Adam(),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy', 'Precision', 'Recall'])\n",
        "\n",
        "# Including more callbacks\n",
        "callbacks_list = [early_stopping, reduce_lr, lrate]\n",
        "\n",
        "# Fitting the model\n",
        "history = model.fit(train_data, epochs=100, validation_data=val_data, callbacks=callbacks_list)\n",
        "\n",
        "# Evaluate with additional metrics\n",
        "results = model.evaluate(val_data, return_dict=True)\n",
        "print(f\"Loss: {results['loss']}, Accuracy: {results['accuracy']}, Precision: {results['precision']}, Recall: {results['recall']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8sgLc6XhbEEM",
        "outputId": "e6e602bb-ca96-4505-8e66-22c76552007d"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "6/6 [==============================] - 3s 84ms/step - loss: 20.9105 - accuracy: 0.7108 - precision: 0.7284 - recall: 0.7108 - val_loss: 21.4740 - val_accuracy: 0.5000 - val_precision: 0.5294 - val_recall: 0.4500 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 21.0769 - accuracy: 0.6867 - precision: 0.7000 - recall: 0.6747 - val_loss: 21.8241 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 0.5000 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 19.5561 - accuracy: 0.7711 - precision: 0.7805 - recall: 0.7711 - val_loss: 20.8809 - val_accuracy: 0.5500 - val_precision: 0.5500 - val_recall: 0.5500 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 18.7812 - accuracy: 0.9036 - precision: 0.9136 - recall: 0.8916 - val_loss: 20.0651 - val_accuracy: 0.6500 - val_precision: 0.6842 - val_recall: 0.6500 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 18.2454 - accuracy: 0.9036 - precision: 0.9024 - recall: 0.8916 - val_loss: 19.8874 - val_accuracy: 0.6000 - val_precision: 0.6316 - val_recall: 0.6000 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 17.3600 - accuracy: 0.9398 - precision: 0.9398 - recall: 0.9398 - val_loss: 19.3378 - val_accuracy: 0.5500 - val_precision: 0.5500 - val_recall: 0.5500 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 16.7734 - accuracy: 0.9518 - precision: 0.9512 - recall: 0.9398 - val_loss: 17.9571 - val_accuracy: 0.7500 - val_precision: 0.7500 - val_recall: 0.7500 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 15.9677 - accuracy: 0.9880 - precision: 0.9880 - recall: 0.9880 - val_loss: 17.3027 - val_accuracy: 0.7500 - val_precision: 0.7500 - val_recall: 0.7500 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 15.4593 - accuracy: 0.9398 - precision: 0.9398 - recall: 0.9398 - val_loss: 16.6299 - val_accuracy: 0.8000 - val_precision: 0.8000 - val_recall: 0.8000 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 14.6433 - accuracy: 0.9880 - precision: 0.9880 - recall: 0.9880 - val_loss: 16.4547 - val_accuracy: 0.8000 - val_precision: 0.8000 - val_recall: 0.8000 - lr: 5.0000e-04\n",
            "Epoch 11/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 14.2855 - accuracy: 0.9639 - precision: 0.9639 - recall: 0.9639 - val_loss: 16.1390 - val_accuracy: 0.8000 - val_precision: 0.8000 - val_recall: 0.8000 - lr: 5.0000e-04\n",
            "Epoch 12/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 13.7685 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 15.6963 - val_accuracy: 0.8000 - val_precision: 0.8000 - val_recall: 0.8000 - lr: 5.0000e-04\n",
            "Epoch 13/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 13.4077 - accuracy: 0.9880 - precision: 0.9880 - recall: 0.9880 - val_loss: 14.9548 - val_accuracy: 0.7500 - val_precision: 0.7500 - val_recall: 0.7500 - lr: 5.0000e-04\n",
            "Epoch 14/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 13.0700 - accuracy: 0.9880 - precision: 0.9880 - recall: 0.9880 - val_loss: 14.5084 - val_accuracy: 0.7500 - val_precision: 0.7500 - val_recall: 0.7500 - lr: 1.0000e-04\n",
            "Epoch 15/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 12.6222 - accuracy: 0.9880 - precision: 0.9880 - recall: 0.9880 - val_loss: 14.1882 - val_accuracy: 0.7000 - val_precision: 0.7000 - val_recall: 0.7000 - lr: 5.0000e-04\n",
            "Epoch 16/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 12.4134 - accuracy: 0.9880 - precision: 0.9880 - recall: 0.9880 - val_loss: 13.9105 - val_accuracy: 0.7000 - val_precision: 0.7000 - val_recall: 0.7000 - lr: 5.0000e-04\n",
            "Epoch 17/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 11.8574 - accuracy: 0.9759 - precision: 0.9759 - recall: 0.9759 - val_loss: 13.4569 - val_accuracy: 0.7000 - val_precision: 0.7000 - val_recall: 0.7000 - lr: 5.0000e-04\n",
            "Epoch 18/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 11.4393 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 12.9186 - val_accuracy: 0.7000 - val_precision: 0.7000 - val_recall: 0.7000 - lr: 5.0000e-04\n",
            "Epoch 19/100\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 11.0502 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 12.4775 - val_accuracy: 0.7000 - val_precision: 0.7368 - val_recall: 0.7000 - lr: 1.0000e-04\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 16.6299 - accuracy: 0.8000 - precision: 0.8000 - recall: 0.8000\n",
            "Loss: 16.629886627197266, Accuracy: 0.800000011920929, Precision: 0.800000011920929, Recall: 0.800000011920929\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Finally: Accuracy is above 80%**"
      ],
      "metadata": {
        "id": "aU3BZXj6iU_k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import KFold\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Define a function to create and return a new model instance\n",
        "def create_model():\n",
        "    from tensorflow.keras.models import Sequential\n",
        "    from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "    from tensorflow.keras.regularizers import l1_l2\n",
        "    model = Sequential([\n",
        "        Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3), kernel_regularizer=l1_l2(l1=0.01, l2=0.01)),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling2D(2, 2),\n",
        "        Dropout(0.1),\n",
        "        Conv2D(64, (3, 3), activation='relu', kernel_regularizer=l1_l2(l1=0.01, l2=0.01)),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling2D(2, 2),\n",
        "        Dropout(0.2),\n",
        "        Conv2D(128, (3, 3), activation='relu', kernel_regularizer=l1_l2(l1=0.01, l2=0.01)),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling2D(2, 2),\n",
        "        Dropout(0.3),\n",
        "        Flatten(),\n",
        "        Dense(512, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(8, activation='softmax')  # Ensure the output layer matches the number of classes\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "best_accuracy = 0.0\n",
        "best_model = None\n",
        "\n",
        "num_folds = 5\n",
        "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
        "fold_no = 1\n",
        "\n",
        "for train, test in kfold.split(data, labels):\n",
        "    model = create_model()\n",
        "    model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    history = model.fit(train_data, epochs=100, validation_data=val_data)\n",
        "\n",
        "    scores = model.evaluate(val_data)\n",
        "    if scores[1] > best_accuracy:  # Check if current fold's accuracy is better than the best saved one\n",
        "        best_accuracy = scores[1]\n",
        "        best_model = model\n",
        "        model.save('best_model_fold_{}.h5'.format(fold_no))  # Saving the best model with fold number\n",
        "\n",
        "    fold_no += 1\n",
        "\n",
        "# Optionally save the overall best model from all folds\n",
        "if best_model:\n",
        "    best_model.save('best_overall_model.h5')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2N4pxRObzR0",
        "outputId": "01a13eeb-2e72-4b82-9857-0e0550e0b361"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "6/6 [==============================] - 3s 51ms/step - loss: 37.3606 - accuracy: 0.0482 - val_loss: 33.3535 - val_accuracy: 0.2000\n",
            "Epoch 2/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 34.7518 - accuracy: 0.2289 - val_loss: 33.3033 - val_accuracy: 0.2000\n",
            "Epoch 3/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 34.2527 - accuracy: 0.2771 - val_loss: 33.2736 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 34.0247 - accuracy: 0.3855 - val_loss: 33.2594 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 33.2980 - accuracy: 0.4337 - val_loss: 33.2762 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 32.9754 - accuracy: 0.5301 - val_loss: 33.3183 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 32.5850 - accuracy: 0.5301 - val_loss: 33.3686 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 32.2526 - accuracy: 0.6145 - val_loss: 33.4085 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 31.9026 - accuracy: 0.6988 - val_loss: 33.4424 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 31.5462 - accuracy: 0.6747 - val_loss: 33.4438 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 31.7588 - accuracy: 0.6627 - val_loss: 33.4091 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 31.3185 - accuracy: 0.7349 - val_loss: 33.3698 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 31.4640 - accuracy: 0.6386 - val_loss: 33.3434 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 31.0971 - accuracy: 0.7470 - val_loss: 33.3429 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 31.0100 - accuracy: 0.8313 - val_loss: 33.3462 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 30.6980 - accuracy: 0.8193 - val_loss: 33.3560 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 30.6281 - accuracy: 0.7952 - val_loss: 33.3524 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 30.4390 - accuracy: 0.8916 - val_loss: 33.3569 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 30.3681 - accuracy: 0.8675 - val_loss: 33.3431 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 30.1671 - accuracy: 0.8795 - val_loss: 33.3215 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 30.0760 - accuracy: 0.8795 - val_loss: 33.2497 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 30.0312 - accuracy: 0.8795 - val_loss: 33.1412 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 29.8454 - accuracy: 0.9277 - val_loss: 33.0310 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 29.7687 - accuracy: 0.9518 - val_loss: 32.9512 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 29.6999 - accuracy: 0.8916 - val_loss: 32.8471 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 29.4230 - accuracy: 0.9759 - val_loss: 32.7890 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 29.4880 - accuracy: 0.9277 - val_loss: 32.7792 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 29.2719 - accuracy: 0.9639 - val_loss: 32.7326 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 29.2404 - accuracy: 0.8916 - val_loss: 32.6906 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 28.9830 - accuracy: 0.9880 - val_loss: 32.6107 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 28.9511 - accuracy: 0.9398 - val_loss: 32.5010 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 28.9450 - accuracy: 0.9277 - val_loss: 32.3868 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 28.6963 - accuracy: 0.9759 - val_loss: 32.2355 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 28.5744 - accuracy: 0.9759 - val_loss: 32.0813 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 28.6001 - accuracy: 0.9398 - val_loss: 31.9320 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 28.4520 - accuracy: 0.9277 - val_loss: 31.7625 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 28.2866 - accuracy: 0.9759 - val_loss: 31.5722 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 28.2419 - accuracy: 0.9398 - val_loss: 31.3731 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 28.0805 - accuracy: 0.9639 - val_loss: 31.1977 - val_accuracy: 0.0500\n",
            "Epoch 40/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 27.9554 - accuracy: 0.9759 - val_loss: 31.0081 - val_accuracy: 0.0500\n",
            "Epoch 41/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 27.7813 - accuracy: 0.9880 - val_loss: 30.7814 - val_accuracy: 0.0500\n",
            "Epoch 42/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 27.7232 - accuracy: 0.9639 - val_loss: 30.5685 - val_accuracy: 0.1500\n",
            "Epoch 43/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 27.5755 - accuracy: 0.9880 - val_loss: 30.3729 - val_accuracy: 0.1500\n",
            "Epoch 44/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 27.5459 - accuracy: 0.9518 - val_loss: 30.2311 - val_accuracy: 0.1500\n",
            "Epoch 45/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 27.3088 - accuracy: 1.0000 - val_loss: 30.0909 - val_accuracy: 0.1500\n",
            "Epoch 46/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 27.2343 - accuracy: 0.9639 - val_loss: 29.9189 - val_accuracy: 0.1500\n",
            "Epoch 47/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 27.0589 - accuracy: 0.9880 - val_loss: 29.7289 - val_accuracy: 0.1500\n",
            "Epoch 48/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 26.9952 - accuracy: 0.9518 - val_loss: 29.5521 - val_accuracy: 0.1500\n",
            "Epoch 49/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 26.8307 - accuracy: 0.9880 - val_loss: 29.3751 - val_accuracy: 0.1500\n",
            "Epoch 50/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 26.8210 - accuracy: 0.9518 - val_loss: 29.2516 - val_accuracy: 0.1500\n",
            "Epoch 51/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 26.5989 - accuracy: 0.9880 - val_loss: 29.0935 - val_accuracy: 0.1500\n",
            "Epoch 52/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 26.5162 - accuracy: 0.9759 - val_loss: 28.9106 - val_accuracy: 0.1500\n",
            "Epoch 53/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 26.3480 - accuracy: 1.0000 - val_loss: 28.7228 - val_accuracy: 0.1500\n",
            "Epoch 54/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 26.2606 - accuracy: 0.9880 - val_loss: 28.5364 - val_accuracy: 0.2000\n",
            "Epoch 55/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 26.1317 - accuracy: 0.9759 - val_loss: 28.3745 - val_accuracy: 0.2000\n",
            "Epoch 56/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 25.9923 - accuracy: 1.0000 - val_loss: 28.2101 - val_accuracy: 0.2000\n",
            "Epoch 57/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 25.9173 - accuracy: 0.9639 - val_loss: 28.0629 - val_accuracy: 0.2000\n",
            "Epoch 58/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 25.7572 - accuracy: 0.9880 - val_loss: 27.9202 - val_accuracy: 0.2000\n",
            "Epoch 59/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 25.6195 - accuracy: 0.9880 - val_loss: 27.7801 - val_accuracy: 0.2500\n",
            "Epoch 60/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 25.5165 - accuracy: 0.9759 - val_loss: 27.6036 - val_accuracy: 0.2500\n",
            "Epoch 61/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 25.3487 - accuracy: 1.0000 - val_loss: 27.4302 - val_accuracy: 0.2500\n",
            "Epoch 62/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 25.2291 - accuracy: 1.0000 - val_loss: 27.2511 - val_accuracy: 0.2500\n",
            "Epoch 63/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 25.1300 - accuracy: 0.9880 - val_loss: 27.0574 - val_accuracy: 0.3000\n",
            "Epoch 64/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 25.0094 - accuracy: 0.9880 - val_loss: 26.8804 - val_accuracy: 0.3500\n",
            "Epoch 65/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 24.8407 - accuracy: 1.0000 - val_loss: 26.7117 - val_accuracy: 0.4000\n",
            "Epoch 66/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 24.7236 - accuracy: 1.0000 - val_loss: 26.5471 - val_accuracy: 0.4500\n",
            "Epoch 67/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 24.5918 - accuracy: 0.9880 - val_loss: 26.3734 - val_accuracy: 0.4500\n",
            "Epoch 68/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 24.4767 - accuracy: 1.0000 - val_loss: 26.2032 - val_accuracy: 0.4500\n",
            "Epoch 69/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 24.3519 - accuracy: 0.9880 - val_loss: 26.0404 - val_accuracy: 0.5500\n",
            "Epoch 70/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 24.2360 - accuracy: 0.9759 - val_loss: 25.8834 - val_accuracy: 0.5500\n",
            "Epoch 71/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 24.1036 - accuracy: 0.9759 - val_loss: 25.7304 - val_accuracy: 0.6000\n",
            "Epoch 72/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 23.9637 - accuracy: 1.0000 - val_loss: 25.5738 - val_accuracy: 0.6000\n",
            "Epoch 73/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 23.8483 - accuracy: 0.9759 - val_loss: 25.4074 - val_accuracy: 0.6000\n",
            "Epoch 74/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 23.6875 - accuracy: 1.0000 - val_loss: 25.2395 - val_accuracy: 0.6000\n",
            "Epoch 75/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 23.5641 - accuracy: 1.0000 - val_loss: 25.0708 - val_accuracy: 0.6000\n",
            "Epoch 76/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 23.4616 - accuracy: 0.9639 - val_loss: 24.8955 - val_accuracy: 0.6000\n",
            "Epoch 77/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 23.3125 - accuracy: 0.9880 - val_loss: 24.7290 - val_accuracy: 0.6500\n",
            "Epoch 78/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 23.1599 - accuracy: 0.9880 - val_loss: 24.5617 - val_accuracy: 0.6500\n",
            "Epoch 79/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 23.0390 - accuracy: 1.0000 - val_loss: 24.3912 - val_accuracy: 0.7000\n",
            "Epoch 80/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 22.9054 - accuracy: 1.0000 - val_loss: 24.2268 - val_accuracy: 0.7000\n",
            "Epoch 81/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 22.8014 - accuracy: 1.0000 - val_loss: 24.0787 - val_accuracy: 0.7000\n",
            "Epoch 82/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 22.6388 - accuracy: 1.0000 - val_loss: 23.9297 - val_accuracy: 0.7000\n",
            "Epoch 83/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 22.5229 - accuracy: 0.9880 - val_loss: 23.7562 - val_accuracy: 0.7000\n",
            "Epoch 84/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 22.4445 - accuracy: 0.9639 - val_loss: 23.6073 - val_accuracy: 0.7000\n",
            "Epoch 85/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 22.2406 - accuracy: 1.0000 - val_loss: 23.4631 - val_accuracy: 0.7000\n",
            "Epoch 86/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 22.1352 - accuracy: 0.9880 - val_loss: 23.3187 - val_accuracy: 0.7000\n",
            "Epoch 87/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 21.9750 - accuracy: 1.0000 - val_loss: 23.1698 - val_accuracy: 0.7000\n",
            "Epoch 88/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 21.8529 - accuracy: 1.0000 - val_loss: 23.0215 - val_accuracy: 0.7000\n",
            "Epoch 89/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 21.7118 - accuracy: 1.0000 - val_loss: 22.8738 - val_accuracy: 0.7000\n",
            "Epoch 90/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 21.5683 - accuracy: 1.0000 - val_loss: 22.7287 - val_accuracy: 0.7000\n",
            "Epoch 91/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 21.4585 - accuracy: 0.9880 - val_loss: 22.5946 - val_accuracy: 0.7000\n",
            "Epoch 92/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 21.3632 - accuracy: 0.9759 - val_loss: 22.4613 - val_accuracy: 0.7000\n",
            "Epoch 93/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 21.2005 - accuracy: 0.9880 - val_loss: 22.3170 - val_accuracy: 0.7000\n",
            "Epoch 94/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 21.0456 - accuracy: 1.0000 - val_loss: 22.1678 - val_accuracy: 0.7000\n",
            "Epoch 95/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 20.9069 - accuracy: 1.0000 - val_loss: 22.0178 - val_accuracy: 0.7000\n",
            "Epoch 96/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 20.7703 - accuracy: 1.0000 - val_loss: 21.8712 - val_accuracy: 0.7000\n",
            "Epoch 97/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 20.6306 - accuracy: 1.0000 - val_loss: 21.7289 - val_accuracy: 0.7500\n",
            "Epoch 98/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 20.5081 - accuracy: 1.0000 - val_loss: 21.5933 - val_accuracy: 0.7500\n",
            "Epoch 99/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 20.3739 - accuracy: 1.0000 - val_loss: 21.4498 - val_accuracy: 0.7500\n",
            "Epoch 100/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 20.2441 - accuracy: 1.0000 - val_loss: 21.3104 - val_accuracy: 0.7500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 21.3104 - accuracy: 0.7500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "6/6 [==============================] - 3s 50ms/step - loss: 36.8247 - accuracy: 0.0964 - val_loss: 33.3670 - val_accuracy: 0.4000\n",
            "Epoch 2/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 34.2743 - accuracy: 0.3012 - val_loss: 33.3343 - val_accuracy: 0.1000\n",
            "Epoch 3/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 34.0453 - accuracy: 0.3012 - val_loss: 33.3642 - val_accuracy: 0.1000\n",
            "Epoch 4/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 33.7595 - accuracy: 0.3976 - val_loss: 33.4201 - val_accuracy: 0.1000\n",
            "Epoch 5/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 32.7510 - accuracy: 0.4699 - val_loss: 33.4803 - val_accuracy: 0.1000\n",
            "Epoch 6/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 32.9606 - accuracy: 0.4337 - val_loss: 33.5438 - val_accuracy: 0.1000\n",
            "Epoch 7/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 32.4283 - accuracy: 0.5542 - val_loss: 33.5844 - val_accuracy: 0.1000\n",
            "Epoch 8/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 31.9745 - accuracy: 0.6747 - val_loss: 33.6356 - val_accuracy: 0.1000\n",
            "Epoch 9/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 31.7308 - accuracy: 0.7108 - val_loss: 33.7157 - val_accuracy: 0.1000\n",
            "Epoch 10/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 31.5871 - accuracy: 0.7229 - val_loss: 33.7905 - val_accuracy: 0.1000\n",
            "Epoch 11/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 31.5768 - accuracy: 0.7952 - val_loss: 33.9068 - val_accuracy: 0.1000\n",
            "Epoch 12/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 31.2656 - accuracy: 0.7590 - val_loss: 34.0418 - val_accuracy: 0.1000\n",
            "Epoch 13/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 31.1534 - accuracy: 0.7831 - val_loss: 34.1939 - val_accuracy: 0.1000\n",
            "Epoch 14/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 30.9978 - accuracy: 0.8193 - val_loss: 34.2418 - val_accuracy: 0.1000\n",
            "Epoch 15/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 31.0011 - accuracy: 0.7831 - val_loss: 34.3103 - val_accuracy: 0.1000\n",
            "Epoch 16/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 30.8103 - accuracy: 0.8313 - val_loss: 34.3333 - val_accuracy: 0.1000\n",
            "Epoch 17/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 30.7032 - accuracy: 0.8554 - val_loss: 34.3841 - val_accuracy: 0.1000\n",
            "Epoch 18/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 30.6645 - accuracy: 0.8072 - val_loss: 34.4156 - val_accuracy: 0.1000\n",
            "Epoch 19/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 30.3836 - accuracy: 0.9036 - val_loss: 34.4133 - val_accuracy: 0.1000\n",
            "Epoch 20/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 30.4974 - accuracy: 0.8313 - val_loss: 34.5431 - val_accuracy: 0.1000\n",
            "Epoch 21/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 30.0630 - accuracy: 0.9398 - val_loss: 34.6385 - val_accuracy: 0.1000\n",
            "Epoch 22/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 30.0515 - accuracy: 0.9277 - val_loss: 34.6652 - val_accuracy: 0.1000\n",
            "Epoch 23/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 29.9372 - accuracy: 0.9277 - val_loss: 34.6314 - val_accuracy: 0.1000\n",
            "Epoch 24/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 29.8050 - accuracy: 0.9277 - val_loss: 34.6152 - val_accuracy: 0.1000\n",
            "Epoch 25/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 29.8274 - accuracy: 0.9157 - val_loss: 34.5597 - val_accuracy: 0.1000\n",
            "Epoch 26/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 29.7287 - accuracy: 0.8916 - val_loss: 34.5048 - val_accuracy: 0.1000\n",
            "Epoch 27/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 29.5771 - accuracy: 0.9398 - val_loss: 34.4451 - val_accuracy: 0.1000\n",
            "Epoch 28/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 29.4665 - accuracy: 0.9277 - val_loss: 34.3622 - val_accuracy: 0.1000\n",
            "Epoch 29/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 29.3459 - accuracy: 0.9398 - val_loss: 34.2900 - val_accuracy: 0.1000\n",
            "Epoch 30/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 29.1843 - accuracy: 0.9518 - val_loss: 34.2251 - val_accuracy: 0.1000\n",
            "Epoch 31/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 29.0880 - accuracy: 0.9518 - val_loss: 34.1573 - val_accuracy: 0.1000\n",
            "Epoch 32/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 29.0106 - accuracy: 0.9639 - val_loss: 34.0938 - val_accuracy: 0.1000\n",
            "Epoch 33/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 28.9254 - accuracy: 0.9398 - val_loss: 34.0395 - val_accuracy: 0.1000\n",
            "Epoch 34/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 28.7909 - accuracy: 0.9518 - val_loss: 33.8991 - val_accuracy: 0.1000\n",
            "Epoch 35/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 28.6738 - accuracy: 0.9398 - val_loss: 33.7400 - val_accuracy: 0.1000\n",
            "Epoch 36/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 28.4966 - accuracy: 0.9880 - val_loss: 33.6205 - val_accuracy: 0.1000\n",
            "Epoch 37/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 28.4268 - accuracy: 0.9639 - val_loss: 33.4961 - val_accuracy: 0.1000\n",
            "Epoch 38/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 28.3039 - accuracy: 0.9639 - val_loss: 33.3174 - val_accuracy: 0.1000\n",
            "Epoch 39/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 28.1807 - accuracy: 1.0000 - val_loss: 33.0417 - val_accuracy: 0.1000\n",
            "Epoch 40/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 28.0948 - accuracy: 0.9759 - val_loss: 32.8310 - val_accuracy: 0.1000\n",
            "Epoch 41/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 27.9954 - accuracy: 0.9639 - val_loss: 32.6974 - val_accuracy: 0.1000\n",
            "Epoch 42/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 27.8701 - accuracy: 0.9639 - val_loss: 32.5131 - val_accuracy: 0.1000\n",
            "Epoch 43/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 27.7521 - accuracy: 0.9518 - val_loss: 32.3504 - val_accuracy: 0.1000\n",
            "Epoch 44/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 27.6368 - accuracy: 0.9759 - val_loss: 32.2278 - val_accuracy: 0.1000\n",
            "Epoch 45/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 27.5492 - accuracy: 0.9639 - val_loss: 32.1250 - val_accuracy: 0.1000\n",
            "Epoch 46/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 27.4526 - accuracy: 0.9518 - val_loss: 32.1323 - val_accuracy: 0.1000\n",
            "Epoch 47/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 27.2679 - accuracy: 0.9880 - val_loss: 31.9873 - val_accuracy: 0.1000\n",
            "Epoch 48/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 27.1864 - accuracy: 0.9759 - val_loss: 31.7652 - val_accuracy: 0.1000\n",
            "Epoch 49/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 27.1416 - accuracy: 0.9639 - val_loss: 31.3998 - val_accuracy: 0.1000\n",
            "Epoch 50/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 26.8754 - accuracy: 1.0000 - val_loss: 31.0976 - val_accuracy: 0.1000\n",
            "Epoch 51/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 26.7510 - accuracy: 1.0000 - val_loss: 30.8376 - val_accuracy: 0.1000\n",
            "Epoch 52/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 26.6794 - accuracy: 0.9880 - val_loss: 30.6123 - val_accuracy: 0.1000\n",
            "Epoch 53/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 26.5373 - accuracy: 1.0000 - val_loss: 30.3583 - val_accuracy: 0.1000\n",
            "Epoch 54/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 26.4100 - accuracy: 1.0000 - val_loss: 30.1464 - val_accuracy: 0.1000\n",
            "Epoch 55/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 26.3071 - accuracy: 0.9880 - val_loss: 29.9559 - val_accuracy: 0.1000\n",
            "Epoch 56/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 26.1972 - accuracy: 0.9759 - val_loss: 29.8167 - val_accuracy: 0.1000\n",
            "Epoch 57/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 26.0480 - accuracy: 0.9880 - val_loss: 29.6397 - val_accuracy: 0.1000\n",
            "Epoch 58/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 25.9201 - accuracy: 1.0000 - val_loss: 29.4400 - val_accuracy: 0.1000\n",
            "Epoch 59/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 25.8012 - accuracy: 0.9880 - val_loss: 29.2334 - val_accuracy: 0.1000\n",
            "Epoch 60/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 25.6579 - accuracy: 1.0000 - val_loss: 29.0502 - val_accuracy: 0.1000\n",
            "Epoch 61/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 25.5712 - accuracy: 0.9880 - val_loss: 28.8428 - val_accuracy: 0.1000\n",
            "Epoch 62/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 25.4088 - accuracy: 0.9880 - val_loss: 28.6218 - val_accuracy: 0.1000\n",
            "Epoch 63/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 25.2933 - accuracy: 0.9880 - val_loss: 28.4021 - val_accuracy: 0.1000\n",
            "Epoch 64/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 25.1530 - accuracy: 1.0000 - val_loss: 28.1550 - val_accuracy: 0.1000\n",
            "Epoch 65/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 25.0071 - accuracy: 1.0000 - val_loss: 27.8947 - val_accuracy: 0.1000\n",
            "Epoch 66/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 24.8915 - accuracy: 1.0000 - val_loss: 27.6366 - val_accuracy: 0.1000\n",
            "Epoch 67/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 24.7839 - accuracy: 0.9759 - val_loss: 27.4030 - val_accuracy: 0.1000\n",
            "Epoch 68/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 24.6600 - accuracy: 0.9759 - val_loss: 27.1832 - val_accuracy: 0.1000\n",
            "Epoch 69/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 24.5586 - accuracy: 0.9639 - val_loss: 26.9947 - val_accuracy: 0.1000\n",
            "Epoch 70/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 24.3656 - accuracy: 1.0000 - val_loss: 26.7871 - val_accuracy: 0.1500\n",
            "Epoch 71/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 24.2462 - accuracy: 0.9880 - val_loss: 26.5714 - val_accuracy: 0.1500\n",
            "Epoch 72/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 24.1146 - accuracy: 0.9880 - val_loss: 26.3268 - val_accuracy: 0.2000\n",
            "Epoch 73/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 23.9616 - accuracy: 1.0000 - val_loss: 26.0892 - val_accuracy: 0.2000\n",
            "Epoch 74/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 23.8458 - accuracy: 0.9880 - val_loss: 25.8701 - val_accuracy: 0.2000\n",
            "Epoch 75/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 23.7397 - accuracy: 0.9759 - val_loss: 25.6452 - val_accuracy: 0.2000\n",
            "Epoch 76/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 23.6120 - accuracy: 0.9759 - val_loss: 25.4338 - val_accuracy: 0.2500\n",
            "Epoch 77/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 23.4778 - accuracy: 0.9759 - val_loss: 25.2125 - val_accuracy: 0.2500\n",
            "Epoch 78/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 23.3110 - accuracy: 1.0000 - val_loss: 24.9913 - val_accuracy: 0.3000\n",
            "Epoch 79/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 23.1972 - accuracy: 1.0000 - val_loss: 24.7604 - val_accuracy: 0.4000\n",
            "Epoch 80/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 23.0472 - accuracy: 1.0000 - val_loss: 24.5499 - val_accuracy: 0.4500\n",
            "Epoch 81/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 22.9254 - accuracy: 0.9759 - val_loss: 24.3438 - val_accuracy: 0.4500\n",
            "Epoch 82/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 22.7909 - accuracy: 0.9880 - val_loss: 24.1424 - val_accuracy: 0.5000\n",
            "Epoch 83/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 22.6707 - accuracy: 0.9759 - val_loss: 23.9515 - val_accuracy: 0.5500\n",
            "Epoch 84/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 22.4937 - accuracy: 1.0000 - val_loss: 23.7644 - val_accuracy: 0.6500\n",
            "Epoch 85/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 22.3714 - accuracy: 0.9880 - val_loss: 23.5801 - val_accuracy: 0.6500\n",
            "Epoch 86/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 22.2341 - accuracy: 1.0000 - val_loss: 23.3937 - val_accuracy: 0.7000\n",
            "Epoch 87/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 22.0860 - accuracy: 1.0000 - val_loss: 23.2146 - val_accuracy: 0.7500\n",
            "Epoch 88/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 21.9512 - accuracy: 1.0000 - val_loss: 23.0433 - val_accuracy: 0.7500\n",
            "Epoch 89/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 21.8422 - accuracy: 0.9759 - val_loss: 22.8814 - val_accuracy: 0.7500\n",
            "Epoch 90/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 21.6758 - accuracy: 1.0000 - val_loss: 22.7192 - val_accuracy: 0.7500\n",
            "Epoch 91/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 21.5510 - accuracy: 1.0000 - val_loss: 22.5587 - val_accuracy: 0.7500\n",
            "Epoch 92/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 21.4186 - accuracy: 0.9880 - val_loss: 22.3980 - val_accuracy: 0.7500\n",
            "Epoch 93/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 21.2708 - accuracy: 1.0000 - val_loss: 22.2387 - val_accuracy: 0.7500\n",
            "Epoch 94/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 21.1427 - accuracy: 0.9880 - val_loss: 22.0902 - val_accuracy: 0.7500\n",
            "Epoch 95/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 21.0274 - accuracy: 0.9880 - val_loss: 21.9443 - val_accuracy: 0.7500\n",
            "Epoch 96/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 20.8855 - accuracy: 0.9880 - val_loss: 21.8073 - val_accuracy: 0.7500\n",
            "Epoch 97/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 20.7428 - accuracy: 0.9880 - val_loss: 21.6673 - val_accuracy: 0.7500\n",
            "Epoch 98/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 20.5943 - accuracy: 1.0000 - val_loss: 21.5280 - val_accuracy: 0.7500\n",
            "Epoch 99/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 20.4536 - accuracy: 1.0000 - val_loss: 21.3863 - val_accuracy: 0.7500\n",
            "Epoch 100/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 20.3151 - accuracy: 1.0000 - val_loss: 21.2442 - val_accuracy: 0.7500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 21.2442 - accuracy: 0.7500\n",
            "Epoch 1/100\n",
            "6/6 [==============================] - 3s 54ms/step - loss: 37.4009 - accuracy: 0.0602 - val_loss: 33.3769 - val_accuracy: 0.1000\n",
            "Epoch 2/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 34.6159 - accuracy: 0.2410 - val_loss: 33.3081 - val_accuracy: 0.0500\n",
            "Epoch 3/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 34.3189 - accuracy: 0.2771 - val_loss: 33.2801 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 33.4884 - accuracy: 0.3373 - val_loss: 33.2808 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 33.1086 - accuracy: 0.4578 - val_loss: 33.2996 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 32.4650 - accuracy: 0.4940 - val_loss: 33.2994 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 32.3929 - accuracy: 0.5904 - val_loss: 33.3246 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 31.9199 - accuracy: 0.6747 - val_loss: 33.4076 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 31.7010 - accuracy: 0.7229 - val_loss: 33.5007 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 31.6357 - accuracy: 0.7229 - val_loss: 33.5450 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 31.5972 - accuracy: 0.7108 - val_loss: 33.5476 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 31.1511 - accuracy: 0.8193 - val_loss: 33.5203 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 30.9352 - accuracy: 0.8313 - val_loss: 33.5190 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 31.2769 - accuracy: 0.7108 - val_loss: 33.5235 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 31.0308 - accuracy: 0.8313 - val_loss: 33.5801 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 30.7506 - accuracy: 0.8434 - val_loss: 33.5674 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 30.4448 - accuracy: 0.8916 - val_loss: 33.5289 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 30.4363 - accuracy: 0.8554 - val_loss: 33.4944 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 30.1637 - accuracy: 0.9398 - val_loss: 33.4609 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 30.1869 - accuracy: 0.8554 - val_loss: 33.4333 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 30.0913 - accuracy: 0.8675 - val_loss: 33.3867 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 29.8764 - accuracy: 0.9398 - val_loss: 33.2895 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 29.7209 - accuracy: 0.9518 - val_loss: 33.2171 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 29.6678 - accuracy: 0.9398 - val_loss: 33.1150 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 29.4677 - accuracy: 0.9759 - val_loss: 33.0345 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 29.4510 - accuracy: 0.9398 - val_loss: 32.9744 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 29.2605 - accuracy: 0.9639 - val_loss: 32.9021 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 29.1626 - accuracy: 0.9759 - val_loss: 32.8259 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 28.9855 - accuracy: 0.9880 - val_loss: 32.7129 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 28.9464 - accuracy: 0.9639 - val_loss: 32.5989 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 28.8690 - accuracy: 0.9157 - val_loss: 32.5611 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 28.6537 - accuracy: 0.9639 - val_loss: 32.4667 - val_accuracy: 0.0500\n",
            "Epoch 33/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 28.6391 - accuracy: 0.9277 - val_loss: 32.3135 - val_accuracy: 0.1000\n",
            "Epoch 34/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 28.4184 - accuracy: 0.9880 - val_loss: 32.1430 - val_accuracy: 0.1000\n",
            "Epoch 35/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 28.2772 - accuracy: 0.9759 - val_loss: 31.9240 - val_accuracy: 0.1000\n",
            "Epoch 36/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 28.2494 - accuracy: 0.9639 - val_loss: 31.7764 - val_accuracy: 0.1000\n",
            "Epoch 37/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 28.0756 - accuracy: 0.9880 - val_loss: 31.6362 - val_accuracy: 0.1000\n",
            "Epoch 38/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 27.9476 - accuracy: 0.9639 - val_loss: 31.4991 - val_accuracy: 0.1000\n",
            "Epoch 39/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 27.8222 - accuracy: 0.9759 - val_loss: 31.3334 - val_accuracy: 0.1000\n",
            "Epoch 40/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 27.6761 - accuracy: 0.9759 - val_loss: 31.1711 - val_accuracy: 0.1000\n",
            "Epoch 41/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 27.5619 - accuracy: 0.9759 - val_loss: 31.0034 - val_accuracy: 0.1000\n",
            "Epoch 42/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 27.5115 - accuracy: 0.9639 - val_loss: 30.8273 - val_accuracy: 0.1000\n",
            "Epoch 43/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 27.3465 - accuracy: 0.9518 - val_loss: 30.5954 - val_accuracy: 0.1500\n",
            "Epoch 44/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 27.1751 - accuracy: 0.9880 - val_loss: 30.3627 - val_accuracy: 0.1500\n",
            "Epoch 45/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 27.1224 - accuracy: 0.9639 - val_loss: 30.1067 - val_accuracy: 0.1500\n",
            "Epoch 46/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 26.9551 - accuracy: 0.9518 - val_loss: 29.8834 - val_accuracy: 0.1500\n",
            "Epoch 47/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 26.8124 - accuracy: 0.9759 - val_loss: 29.7204 - val_accuracy: 0.1000\n",
            "Epoch 48/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 26.7211 - accuracy: 0.9639 - val_loss: 29.5301 - val_accuracy: 0.1000\n",
            "Epoch 49/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 26.6337 - accuracy: 0.9639 - val_loss: 29.3597 - val_accuracy: 0.1000\n",
            "Epoch 50/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 26.3809 - accuracy: 1.0000 - val_loss: 29.2320 - val_accuracy: 0.1000\n",
            "Epoch 51/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 26.2513 - accuracy: 0.9880 - val_loss: 29.0924 - val_accuracy: 0.1000\n",
            "Epoch 52/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 26.1623 - accuracy: 0.9880 - val_loss: 28.8527 - val_accuracy: 0.1000\n",
            "Epoch 53/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 25.9885 - accuracy: 1.0000 - val_loss: 28.6319 - val_accuracy: 0.1000\n",
            "Epoch 54/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 25.8601 - accuracy: 1.0000 - val_loss: 28.4388 - val_accuracy: 0.1000\n",
            "Epoch 55/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 25.7229 - accuracy: 1.0000 - val_loss: 28.2641 - val_accuracy: 0.1000\n",
            "Epoch 56/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 25.6252 - accuracy: 0.9880 - val_loss: 28.0830 - val_accuracy: 0.1000\n",
            "Epoch 57/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 25.4855 - accuracy: 0.9880 - val_loss: 27.9169 - val_accuracy: 0.1000\n",
            "Epoch 58/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 25.3151 - accuracy: 1.0000 - val_loss: 27.7562 - val_accuracy: 0.1500\n",
            "Epoch 59/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 25.2297 - accuracy: 0.9759 - val_loss: 27.6014 - val_accuracy: 0.1500\n",
            "Epoch 60/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 25.1113 - accuracy: 0.9759 - val_loss: 27.4109 - val_accuracy: 0.2000\n",
            "Epoch 61/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 24.9194 - accuracy: 1.0000 - val_loss: 27.2024 - val_accuracy: 0.2000\n",
            "Epoch 62/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 24.7758 - accuracy: 1.0000 - val_loss: 27.0236 - val_accuracy: 0.2000\n",
            "Epoch 63/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 24.7010 - accuracy: 0.9759 - val_loss: 26.8647 - val_accuracy: 0.2000\n",
            "Epoch 64/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 24.4968 - accuracy: 1.0000 - val_loss: 26.7076 - val_accuracy: 0.2000\n",
            "Epoch 65/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 24.3750 - accuracy: 0.9880 - val_loss: 26.5515 - val_accuracy: 0.2500\n",
            "Epoch 66/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 24.2230 - accuracy: 1.0000 - val_loss: 26.3968 - val_accuracy: 0.2500\n",
            "Epoch 67/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 24.1280 - accuracy: 0.9880 - val_loss: 26.2415 - val_accuracy: 0.2500\n",
            "Epoch 68/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 23.9500 - accuracy: 1.0000 - val_loss: 26.0523 - val_accuracy: 0.2500\n",
            "Epoch 69/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 23.7984 - accuracy: 1.0000 - val_loss: 25.8638 - val_accuracy: 0.2500\n",
            "Epoch 70/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 23.6595 - accuracy: 1.0000 - val_loss: 25.6789 - val_accuracy: 0.3000\n",
            "Epoch 71/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 23.5533 - accuracy: 0.9759 - val_loss: 25.4997 - val_accuracy: 0.3500\n",
            "Epoch 72/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 23.3804 - accuracy: 1.0000 - val_loss: 25.3200 - val_accuracy: 0.3500\n",
            "Epoch 73/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 23.2763 - accuracy: 0.9759 - val_loss: 25.1315 - val_accuracy: 0.3500\n",
            "Epoch 74/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 23.0975 - accuracy: 1.0000 - val_loss: 24.9531 - val_accuracy: 0.4000\n",
            "Epoch 75/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 22.9605 - accuracy: 1.0000 - val_loss: 24.7660 - val_accuracy: 0.3500\n",
            "Epoch 76/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 22.8584 - accuracy: 0.9880 - val_loss: 24.5670 - val_accuracy: 0.4000\n",
            "Epoch 77/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 22.6716 - accuracy: 1.0000 - val_loss: 24.3844 - val_accuracy: 0.4000\n",
            "Epoch 78/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 22.5334 - accuracy: 1.0000 - val_loss: 24.2086 - val_accuracy: 0.4000\n",
            "Epoch 79/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 22.4125 - accuracy: 0.9880 - val_loss: 24.0460 - val_accuracy: 0.4000\n",
            "Epoch 80/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 22.2454 - accuracy: 1.0000 - val_loss: 23.8751 - val_accuracy: 0.4000\n",
            "Epoch 81/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 22.1172 - accuracy: 0.9880 - val_loss: 23.6774 - val_accuracy: 0.3500\n",
            "Epoch 82/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 21.9588 - accuracy: 1.0000 - val_loss: 23.4887 - val_accuracy: 0.3500\n",
            "Epoch 83/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 21.8335 - accuracy: 0.9880 - val_loss: 23.3119 - val_accuracy: 0.3500\n",
            "Epoch 84/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 21.6803 - accuracy: 0.9880 - val_loss: 23.1341 - val_accuracy: 0.3500\n",
            "Epoch 85/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 21.5323 - accuracy: 1.0000 - val_loss: 22.9574 - val_accuracy: 0.4500\n",
            "Epoch 86/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 21.3940 - accuracy: 0.9880 - val_loss: 22.7879 - val_accuracy: 0.4500\n",
            "Epoch 87/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 21.2397 - accuracy: 1.0000 - val_loss: 22.6214 - val_accuracy: 0.5000\n",
            "Epoch 88/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 21.1211 - accuracy: 0.9759 - val_loss: 22.4476 - val_accuracy: 0.4500\n",
            "Epoch 89/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 20.9838 - accuracy: 0.9880 - val_loss: 22.2810 - val_accuracy: 0.5000\n",
            "Epoch 90/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 20.8791 - accuracy: 0.9880 - val_loss: 22.1149 - val_accuracy: 0.5000\n",
            "Epoch 91/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 20.7319 - accuracy: 0.9759 - val_loss: 21.9613 - val_accuracy: 0.5000\n",
            "Epoch 92/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 20.5296 - accuracy: 1.0000 - val_loss: 21.8067 - val_accuracy: 0.5000\n",
            "Epoch 93/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 20.3753 - accuracy: 1.0000 - val_loss: 21.6441 - val_accuracy: 0.5000\n",
            "Epoch 94/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 20.2355 - accuracy: 1.0000 - val_loss: 21.4853 - val_accuracy: 0.5000\n",
            "Epoch 95/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 20.1226 - accuracy: 0.9880 - val_loss: 21.3205 - val_accuracy: 0.5000\n",
            "Epoch 96/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 19.9453 - accuracy: 1.0000 - val_loss: 21.1553 - val_accuracy: 0.5000\n",
            "Epoch 97/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 19.7944 - accuracy: 1.0000 - val_loss: 20.9917 - val_accuracy: 0.5500\n",
            "Epoch 98/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 19.6957 - accuracy: 0.9759 - val_loss: 20.8040 - val_accuracy: 0.6000\n",
            "Epoch 99/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 19.5243 - accuracy: 1.0000 - val_loss: 20.6173 - val_accuracy: 0.6500\n",
            "Epoch 100/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 19.3727 - accuracy: 1.0000 - val_loss: 20.4393 - val_accuracy: 0.6500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 20.4393 - accuracy: 0.6500\n",
            "Epoch 1/100\n",
            "6/6 [==============================] - 3s 51ms/step - loss: 37.1729 - accuracy: 0.0723 - val_loss: 33.3111 - val_accuracy: 0.1000\n",
            "Epoch 2/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 34.5625 - accuracy: 0.3012 - val_loss: 33.2550 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 33.7337 - accuracy: 0.3253 - val_loss: 33.2217 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 33.3918 - accuracy: 0.3855 - val_loss: 33.2048 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 32.7232 - accuracy: 0.5181 - val_loss: 33.1952 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 32.5034 - accuracy: 0.4940 - val_loss: 33.1988 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 32.6775 - accuracy: 0.4940 - val_loss: 33.2203 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 31.8284 - accuracy: 0.6506 - val_loss: 33.2627 - val_accuracy: 0.0500\n",
            "Epoch 9/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 32.0261 - accuracy: 0.6024 - val_loss: 33.2935 - val_accuracy: 0.1000\n",
            "Epoch 10/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 31.8306 - accuracy: 0.6265 - val_loss: 33.2987 - val_accuracy: 0.1500\n",
            "Epoch 11/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 31.4309 - accuracy: 0.7952 - val_loss: 33.2909 - val_accuracy: 0.1500\n",
            "Epoch 12/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 31.2391 - accuracy: 0.7590 - val_loss: 33.2855 - val_accuracy: 0.0500\n",
            "Epoch 13/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 31.1783 - accuracy: 0.7952 - val_loss: 33.2966 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 30.9239 - accuracy: 0.8313 - val_loss: 33.3234 - val_accuracy: 0.1000\n",
            "Epoch 15/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 30.8601 - accuracy: 0.8072 - val_loss: 33.3331 - val_accuracy: 0.1000\n",
            "Epoch 16/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 30.5896 - accuracy: 0.8795 - val_loss: 33.3329 - val_accuracy: 0.1500\n",
            "Epoch 17/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 30.5292 - accuracy: 0.8916 - val_loss: 33.3169 - val_accuracy: 0.1500\n",
            "Epoch 18/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 30.5359 - accuracy: 0.8434 - val_loss: 33.3016 - val_accuracy: 0.1500\n",
            "Epoch 19/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 30.4474 - accuracy: 0.8434 - val_loss: 33.2996 - val_accuracy: 0.1500\n",
            "Epoch 20/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 30.1079 - accuracy: 0.9518 - val_loss: 33.2740 - val_accuracy: 0.1500\n",
            "Epoch 21/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 30.1767 - accuracy: 0.8795 - val_loss: 33.1842 - val_accuracy: 0.1500\n",
            "Epoch 22/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 30.0461 - accuracy: 0.8675 - val_loss: 33.1046 - val_accuracy: 0.1500\n",
            "Epoch 23/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 29.9251 - accuracy: 0.9157 - val_loss: 33.0859 - val_accuracy: 0.1500\n",
            "Epoch 24/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 29.8882 - accuracy: 0.8675 - val_loss: 33.0883 - val_accuracy: 0.1500\n",
            "Epoch 25/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 29.7101 - accuracy: 0.9277 - val_loss: 33.0951 - val_accuracy: 0.1500\n",
            "Epoch 26/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 29.5332 - accuracy: 0.9157 - val_loss: 33.0691 - val_accuracy: 0.1500\n",
            "Epoch 27/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 29.5186 - accuracy: 0.8916 - val_loss: 32.9509 - val_accuracy: 0.1500\n",
            "Epoch 28/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 29.2968 - accuracy: 0.9518 - val_loss: 32.7777 - val_accuracy: 0.1500\n",
            "Epoch 29/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 29.1981 - accuracy: 0.9518 - val_loss: 32.6575 - val_accuracy: 0.1500\n",
            "Epoch 30/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 29.0954 - accuracy: 0.9277 - val_loss: 32.5479 - val_accuracy: 0.1500\n",
            "Epoch 31/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 29.0885 - accuracy: 0.8916 - val_loss: 32.4411 - val_accuracy: 0.1500\n",
            "Epoch 32/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 28.8706 - accuracy: 0.9518 - val_loss: 32.3967 - val_accuracy: 0.1500\n",
            "Epoch 33/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 28.8800 - accuracy: 0.9157 - val_loss: 32.3171 - val_accuracy: 0.1500\n",
            "Epoch 34/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 28.6883 - accuracy: 0.9157 - val_loss: 32.2143 - val_accuracy: 0.1500\n",
            "Epoch 35/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 28.4390 - accuracy: 0.9880 - val_loss: 32.1104 - val_accuracy: 0.1500\n",
            "Epoch 36/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 28.3524 - accuracy: 0.9639 - val_loss: 32.0141 - val_accuracy: 0.1500\n",
            "Epoch 37/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 28.3377 - accuracy: 0.9639 - val_loss: 31.9208 - val_accuracy: 0.1500\n",
            "Epoch 38/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 28.1438 - accuracy: 0.9880 - val_loss: 31.8001 - val_accuracy: 0.1500\n",
            "Epoch 39/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 27.9940 - accuracy: 1.0000 - val_loss: 31.6750 - val_accuracy: 0.1500\n",
            "Epoch 40/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 27.9006 - accuracy: 1.0000 - val_loss: 31.5185 - val_accuracy: 0.1500\n",
            "Epoch 41/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 27.7845 - accuracy: 0.9759 - val_loss: 31.3528 - val_accuracy: 0.1500\n",
            "Epoch 42/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 27.6972 - accuracy: 0.9880 - val_loss: 31.1773 - val_accuracy: 0.1500\n",
            "Epoch 43/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 27.5588 - accuracy: 1.0000 - val_loss: 31.0077 - val_accuracy: 0.1500\n",
            "Epoch 44/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 27.4841 - accuracy: 0.9759 - val_loss: 30.8875 - val_accuracy: 0.1500\n",
            "Epoch 45/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 27.3660 - accuracy: 0.9759 - val_loss: 30.7484 - val_accuracy: 0.1500\n",
            "Epoch 46/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 27.2296 - accuracy: 0.9880 - val_loss: 30.5749 - val_accuracy: 0.1500\n",
            "Epoch 47/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 27.0780 - accuracy: 0.9880 - val_loss: 30.4252 - val_accuracy: 0.1500\n",
            "Epoch 48/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 26.9993 - accuracy: 0.9639 - val_loss: 30.2863 - val_accuracy: 0.2000\n",
            "Epoch 49/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 26.8652 - accuracy: 0.9759 - val_loss: 30.1321 - val_accuracy: 0.2000\n",
            "Epoch 50/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 26.7932 - accuracy: 0.9759 - val_loss: 29.9389 - val_accuracy: 0.2000\n",
            "Epoch 51/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 26.6187 - accuracy: 0.9759 - val_loss: 29.7671 - val_accuracy: 0.2000\n",
            "Epoch 52/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 26.5042 - accuracy: 0.9759 - val_loss: 29.5761 - val_accuracy: 0.2500\n",
            "Epoch 53/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 26.3622 - accuracy: 0.9759 - val_loss: 29.3712 - val_accuracy: 0.2500\n",
            "Epoch 54/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 26.2713 - accuracy: 0.9880 - val_loss: 29.1873 - val_accuracy: 0.2500\n",
            "Epoch 55/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 26.0872 - accuracy: 1.0000 - val_loss: 29.0065 - val_accuracy: 0.2500\n",
            "Epoch 56/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 25.9598 - accuracy: 1.0000 - val_loss: 28.8142 - val_accuracy: 0.2500\n",
            "Epoch 57/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 25.8749 - accuracy: 0.9639 - val_loss: 28.6262 - val_accuracy: 0.2500\n",
            "Epoch 58/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 25.7562 - accuracy: 0.9639 - val_loss: 28.4618 - val_accuracy: 0.2500\n",
            "Epoch 59/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 25.6163 - accuracy: 0.9759 - val_loss: 28.3013 - val_accuracy: 0.2500\n",
            "Epoch 60/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 25.4707 - accuracy: 0.9880 - val_loss: 28.1337 - val_accuracy: 0.3000\n",
            "Epoch 61/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 25.3564 - accuracy: 0.9880 - val_loss: 27.9208 - val_accuracy: 0.3000\n",
            "Epoch 62/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 25.2070 - accuracy: 0.9880 - val_loss: 27.7202 - val_accuracy: 0.3500\n",
            "Epoch 63/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 25.1106 - accuracy: 0.9759 - val_loss: 27.4908 - val_accuracy: 0.3500\n",
            "Epoch 64/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 24.9967 - accuracy: 0.9759 - val_loss: 27.2633 - val_accuracy: 0.3500\n",
            "Epoch 65/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 24.8322 - accuracy: 1.0000 - val_loss: 27.0617 - val_accuracy: 0.3500\n",
            "Epoch 66/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 24.6931 - accuracy: 0.9880 - val_loss: 26.8777 - val_accuracy: 0.3500\n",
            "Epoch 67/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 24.5451 - accuracy: 1.0000 - val_loss: 26.7175 - val_accuracy: 0.3500\n",
            "Epoch 68/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 24.4459 - accuracy: 0.9880 - val_loss: 26.5467 - val_accuracy: 0.4000\n",
            "Epoch 69/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 24.3088 - accuracy: 0.9880 - val_loss: 26.3614 - val_accuracy: 0.4000\n",
            "Epoch 70/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 24.1872 - accuracy: 0.9759 - val_loss: 26.1768 - val_accuracy: 0.4000\n",
            "Epoch 71/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 24.0231 - accuracy: 0.9880 - val_loss: 25.9867 - val_accuracy: 0.4000\n",
            "Epoch 72/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 23.8914 - accuracy: 0.9880 - val_loss: 25.8040 - val_accuracy: 0.4000\n",
            "Epoch 73/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 23.8070 - accuracy: 0.9759 - val_loss: 25.6293 - val_accuracy: 0.4000\n",
            "Epoch 74/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 23.6480 - accuracy: 0.9880 - val_loss: 25.4456 - val_accuracy: 0.4000\n",
            "Epoch 75/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 23.5226 - accuracy: 0.9759 - val_loss: 25.2644 - val_accuracy: 0.4000\n",
            "Epoch 76/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 23.4055 - accuracy: 0.9639 - val_loss: 25.0930 - val_accuracy: 0.4000\n",
            "Epoch 77/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 23.2535 - accuracy: 0.9759 - val_loss: 24.9342 - val_accuracy: 0.4000\n",
            "Epoch 78/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 23.1091 - accuracy: 0.9880 - val_loss: 24.7650 - val_accuracy: 0.4000\n",
            "Epoch 79/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 22.9744 - accuracy: 0.9880 - val_loss: 24.5922 - val_accuracy: 0.4000\n",
            "Epoch 80/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 22.8205 - accuracy: 1.0000 - val_loss: 24.4188 - val_accuracy: 0.4000\n",
            "Epoch 81/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 22.6918 - accuracy: 1.0000 - val_loss: 24.2521 - val_accuracy: 0.5000\n",
            "Epoch 82/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 22.6118 - accuracy: 0.9518 - val_loss: 24.0787 - val_accuracy: 0.5000\n",
            "Epoch 83/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 22.4391 - accuracy: 0.9880 - val_loss: 23.8899 - val_accuracy: 0.5000\n",
            "Epoch 84/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 22.3097 - accuracy: 0.9880 - val_loss: 23.7128 - val_accuracy: 0.5500\n",
            "Epoch 85/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 22.1589 - accuracy: 1.0000 - val_loss: 23.5499 - val_accuracy: 0.5500\n",
            "Epoch 86/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 22.0056 - accuracy: 1.0000 - val_loss: 23.3895 - val_accuracy: 0.6000\n",
            "Epoch 87/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 21.8903 - accuracy: 0.9880 - val_loss: 23.2351 - val_accuracy: 0.6500\n",
            "Epoch 88/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 21.7334 - accuracy: 1.0000 - val_loss: 23.0833 - val_accuracy: 0.6500\n",
            "Epoch 89/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 21.6050 - accuracy: 1.0000 - val_loss: 22.9285 - val_accuracy: 0.6500\n",
            "Epoch 90/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 21.4605 - accuracy: 1.0000 - val_loss: 22.7716 - val_accuracy: 0.6500\n",
            "Epoch 91/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 21.3363 - accuracy: 1.0000 - val_loss: 22.6198 - val_accuracy: 0.6500\n",
            "Epoch 92/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 21.1951 - accuracy: 1.0000 - val_loss: 22.4577 - val_accuracy: 0.6500\n",
            "Epoch 93/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 21.0643 - accuracy: 0.9880 - val_loss: 22.2955 - val_accuracy: 0.6500\n",
            "Epoch 94/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 20.9274 - accuracy: 0.9880 - val_loss: 22.1312 - val_accuracy: 0.6500\n",
            "Epoch 95/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 20.7859 - accuracy: 1.0000 - val_loss: 21.9704 - val_accuracy: 0.6500\n",
            "Epoch 96/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 20.6378 - accuracy: 1.0000 - val_loss: 21.8125 - val_accuracy: 0.6500\n",
            "Epoch 97/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 20.5026 - accuracy: 1.0000 - val_loss: 21.6577 - val_accuracy: 0.6500\n",
            "Epoch 98/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 20.3782 - accuracy: 1.0000 - val_loss: 21.4985 - val_accuracy: 0.6500\n",
            "Epoch 99/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 20.2374 - accuracy: 1.0000 - val_loss: 21.3397 - val_accuracy: 0.6500\n",
            "Epoch 100/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 20.0927 - accuracy: 1.0000 - val_loss: 21.1809 - val_accuracy: 0.6500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 21.1809 - accuracy: 0.6500\n",
            "Epoch 1/100\n",
            "6/6 [==============================] - 3s 54ms/step - loss: 36.3037 - accuracy: 0.1928 - val_loss: 33.3885 - val_accuracy: 0.2000\n",
            "Epoch 2/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 34.3135 - accuracy: 0.2892 - val_loss: 33.3369 - val_accuracy: 0.2000\n",
            "Epoch 3/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 34.5250 - accuracy: 0.3012 - val_loss: 33.2794 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 34.0920 - accuracy: 0.2892 - val_loss: 33.2227 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 32.8103 - accuracy: 0.5542 - val_loss: 33.1687 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 32.6796 - accuracy: 0.5301 - val_loss: 33.1128 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 32.2971 - accuracy: 0.6265 - val_loss: 33.0633 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 32.2698 - accuracy: 0.6386 - val_loss: 33.0144 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 31.7041 - accuracy: 0.7229 - val_loss: 32.9711 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 31.7994 - accuracy: 0.6627 - val_loss: 32.9246 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 31.3757 - accuracy: 0.7711 - val_loss: 32.8673 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 31.3524 - accuracy: 0.7711 - val_loss: 32.7998 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 31.1947 - accuracy: 0.7711 - val_loss: 32.7521 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 30.9283 - accuracy: 0.8795 - val_loss: 32.7185 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 30.9777 - accuracy: 0.8193 - val_loss: 32.6768 - val_accuracy: 0.0500\n",
            "Epoch 16/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 30.7907 - accuracy: 0.8554 - val_loss: 32.5811 - val_accuracy: 0.0500\n",
            "Epoch 17/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 30.7096 - accuracy: 0.8554 - val_loss: 32.4654 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 30.5697 - accuracy: 0.8675 - val_loss: 32.3369 - val_accuracy: 0.0500\n",
            "Epoch 19/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 30.3020 - accuracy: 0.9157 - val_loss: 32.2276 - val_accuracy: 0.0500\n",
            "Epoch 20/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 30.2342 - accuracy: 0.9398 - val_loss: 32.1342 - val_accuracy: 0.0500\n",
            "Epoch 21/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 30.1488 - accuracy: 0.9157 - val_loss: 32.0537 - val_accuracy: 0.1000\n",
            "Epoch 22/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 30.1835 - accuracy: 0.8795 - val_loss: 31.9972 - val_accuracy: 0.0500\n",
            "Epoch 23/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 29.8319 - accuracy: 0.9759 - val_loss: 31.9439 - val_accuracy: 0.0500\n",
            "Epoch 24/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 30.0882 - accuracy: 0.8916 - val_loss: 31.8178 - val_accuracy: 0.0500\n",
            "Epoch 25/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 29.8244 - accuracy: 0.9157 - val_loss: 31.7507 - val_accuracy: 0.2000\n",
            "Epoch 26/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 29.6033 - accuracy: 0.9518 - val_loss: 31.6773 - val_accuracy: 0.2000\n",
            "Epoch 27/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 29.4774 - accuracy: 0.9639 - val_loss: 31.5763 - val_accuracy: 0.2000\n",
            "Epoch 28/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 29.3937 - accuracy: 0.9518 - val_loss: 31.4562 - val_accuracy: 0.2000\n",
            "Epoch 29/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 29.2628 - accuracy: 0.9639 - val_loss: 31.3301 - val_accuracy: 0.2000\n",
            "Epoch 30/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 29.1833 - accuracy: 0.9759 - val_loss: 31.1905 - val_accuracy: 0.2000\n",
            "Epoch 31/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 28.9768 - accuracy: 1.0000 - val_loss: 31.0581 - val_accuracy: 0.2000\n",
            "Epoch 32/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 28.9202 - accuracy: 0.9759 - val_loss: 30.9204 - val_accuracy: 0.2000\n",
            "Epoch 33/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 28.8923 - accuracy: 0.9277 - val_loss: 30.8238 - val_accuracy: 0.2000\n",
            "Epoch 34/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 28.7158 - accuracy: 0.9759 - val_loss: 30.7312 - val_accuracy: 0.2000\n",
            "Epoch 35/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 28.6293 - accuracy: 0.9639 - val_loss: 30.6330 - val_accuracy: 0.2000\n",
            "Epoch 36/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 28.5370 - accuracy: 0.9518 - val_loss: 30.5181 - val_accuracy: 0.2000\n",
            "Epoch 37/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 28.4085 - accuracy: 0.9518 - val_loss: 30.4025 - val_accuracy: 0.2000\n",
            "Epoch 38/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 28.2816 - accuracy: 0.9398 - val_loss: 30.2757 - val_accuracy: 0.2000\n",
            "Epoch 39/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 28.1464 - accuracy: 0.9759 - val_loss: 30.1385 - val_accuracy: 0.2000\n",
            "Epoch 40/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 28.0300 - accuracy: 0.9759 - val_loss: 29.9901 - val_accuracy: 0.2500\n",
            "Epoch 41/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 27.8816 - accuracy: 0.9880 - val_loss: 29.8324 - val_accuracy: 0.3000\n",
            "Epoch 42/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 27.8106 - accuracy: 0.9759 - val_loss: 29.6561 - val_accuracy: 0.3000\n",
            "Epoch 43/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 27.7125 - accuracy: 0.9639 - val_loss: 29.5052 - val_accuracy: 0.3000\n",
            "Epoch 44/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 27.5948 - accuracy: 0.9759 - val_loss: 29.3686 - val_accuracy: 0.3500\n",
            "Epoch 45/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 27.4409 - accuracy: 0.9759 - val_loss: 29.2367 - val_accuracy: 0.4000\n",
            "Epoch 46/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 27.3313 - accuracy: 0.9759 - val_loss: 29.0928 - val_accuracy: 0.4000\n",
            "Epoch 47/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 27.2234 - accuracy: 0.9759 - val_loss: 28.9438 - val_accuracy: 0.4000\n",
            "Epoch 48/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 27.0487 - accuracy: 1.0000 - val_loss: 28.7942 - val_accuracy: 0.4000\n",
            "Epoch 49/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 26.9644 - accuracy: 0.9759 - val_loss: 28.6429 - val_accuracy: 0.4000\n",
            "Epoch 50/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 26.8420 - accuracy: 0.9880 - val_loss: 28.4954 - val_accuracy: 0.4000\n",
            "Epoch 51/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 26.6978 - accuracy: 1.0000 - val_loss: 28.3549 - val_accuracy: 0.4000\n",
            "Epoch 52/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 26.5952 - accuracy: 0.9639 - val_loss: 28.2208 - val_accuracy: 0.4000\n",
            "Epoch 53/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 26.4892 - accuracy: 0.9759 - val_loss: 28.1027 - val_accuracy: 0.4000\n",
            "Epoch 54/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 26.3970 - accuracy: 0.9639 - val_loss: 27.9995 - val_accuracy: 0.4000\n",
            "Epoch 55/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 26.2105 - accuracy: 0.9880 - val_loss: 27.8878 - val_accuracy: 0.4000\n",
            "Epoch 56/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 26.0894 - accuracy: 0.9880 - val_loss: 27.7558 - val_accuracy: 0.4000\n",
            "Epoch 57/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 26.0214 - accuracy: 0.9759 - val_loss: 27.6131 - val_accuracy: 0.4000\n",
            "Epoch 58/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 25.8373 - accuracy: 0.9880 - val_loss: 27.4245 - val_accuracy: 0.4000\n",
            "Epoch 59/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 25.7411 - accuracy: 0.9880 - val_loss: 27.2091 - val_accuracy: 0.4500\n",
            "Epoch 60/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 25.6242 - accuracy: 0.9398 - val_loss: 27.0169 - val_accuracy: 0.4500\n",
            "Epoch 61/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 25.4917 - accuracy: 0.9639 - val_loss: 26.8477 - val_accuracy: 0.4500\n",
            "Epoch 62/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 25.3187 - accuracy: 0.9880 - val_loss: 26.7094 - val_accuracy: 0.5000\n",
            "Epoch 63/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 25.1855 - accuracy: 0.9880 - val_loss: 26.5568 - val_accuracy: 0.5000\n",
            "Epoch 64/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 25.0455 - accuracy: 1.0000 - val_loss: 26.4120 - val_accuracy: 0.5000\n",
            "Epoch 65/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 24.9131 - accuracy: 1.0000 - val_loss: 26.2665 - val_accuracy: 0.5500\n",
            "Epoch 66/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 24.7774 - accuracy: 1.0000 - val_loss: 26.1187 - val_accuracy: 0.5500\n",
            "Epoch 67/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 24.6441 - accuracy: 0.9880 - val_loss: 25.9712 - val_accuracy: 0.5500\n",
            "Epoch 68/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 24.5303 - accuracy: 0.9880 - val_loss: 25.8282 - val_accuracy: 0.5500\n",
            "Epoch 69/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 24.3905 - accuracy: 1.0000 - val_loss: 25.6742 - val_accuracy: 0.5500\n",
            "Epoch 70/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 24.3441 - accuracy: 0.9880 - val_loss: 25.5215 - val_accuracy: 0.6000\n",
            "Epoch 71/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 24.1526 - accuracy: 0.9880 - val_loss: 25.3594 - val_accuracy: 0.6000\n",
            "Epoch 72/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 24.0265 - accuracy: 0.9880 - val_loss: 25.2172 - val_accuracy: 0.6000\n",
            "Epoch 73/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 23.8564 - accuracy: 1.0000 - val_loss: 25.0813 - val_accuracy: 0.6000\n",
            "Epoch 74/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 23.7105 - accuracy: 1.0000 - val_loss: 24.9397 - val_accuracy: 0.6000\n",
            "Epoch 75/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 23.6461 - accuracy: 0.9759 - val_loss: 24.7809 - val_accuracy: 0.6000\n",
            "Epoch 76/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 23.4382 - accuracy: 1.0000 - val_loss: 24.6234 - val_accuracy: 0.6000\n",
            "Epoch 77/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 23.3147 - accuracy: 1.0000 - val_loss: 24.4604 - val_accuracy: 0.6000\n",
            "Epoch 78/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 23.1786 - accuracy: 1.0000 - val_loss: 24.2989 - val_accuracy: 0.6500\n",
            "Epoch 79/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 23.0505 - accuracy: 0.9880 - val_loss: 24.1367 - val_accuracy: 0.6500\n",
            "Epoch 80/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 22.9078 - accuracy: 0.9880 - val_loss: 23.9802 - val_accuracy: 0.7000\n",
            "Epoch 81/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 22.7916 - accuracy: 0.9759 - val_loss: 23.8484 - val_accuracy: 0.6500\n",
            "Epoch 82/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 22.6247 - accuracy: 1.0000 - val_loss: 23.7226 - val_accuracy: 0.6500\n",
            "Epoch 83/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 22.5088 - accuracy: 0.9880 - val_loss: 23.5897 - val_accuracy: 0.6500\n",
            "Epoch 84/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 22.3613 - accuracy: 0.9880 - val_loss: 23.4558 - val_accuracy: 0.6500\n",
            "Epoch 85/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 22.2154 - accuracy: 1.0000 - val_loss: 23.3165 - val_accuracy: 0.6500\n",
            "Epoch 86/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 22.0786 - accuracy: 1.0000 - val_loss: 23.1677 - val_accuracy: 0.6500\n",
            "Epoch 87/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 21.9615 - accuracy: 0.9880 - val_loss: 23.0187 - val_accuracy: 0.6500\n",
            "Epoch 88/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 21.8067 - accuracy: 1.0000 - val_loss: 22.8772 - val_accuracy: 0.6500\n",
            "Epoch 89/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 21.6664 - accuracy: 1.0000 - val_loss: 22.7198 - val_accuracy: 0.6500\n",
            "Epoch 90/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 21.5522 - accuracy: 0.9759 - val_loss: 22.5633 - val_accuracy: 0.7000\n",
            "Epoch 91/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 21.4091 - accuracy: 0.9880 - val_loss: 22.4248 - val_accuracy: 0.6500\n",
            "Epoch 92/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 21.2406 - accuracy: 1.0000 - val_loss: 22.2855 - val_accuracy: 0.6500\n",
            "Epoch 93/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 21.1112 - accuracy: 1.0000 - val_loss: 22.1491 - val_accuracy: 0.6500\n",
            "Epoch 94/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 20.9703 - accuracy: 1.0000 - val_loss: 22.0110 - val_accuracy: 0.6500\n",
            "Epoch 95/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 20.8715 - accuracy: 0.9880 - val_loss: 21.8834 - val_accuracy: 0.6500\n",
            "Epoch 96/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 20.7148 - accuracy: 0.9880 - val_loss: 21.7599 - val_accuracy: 0.6500\n",
            "Epoch 97/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 20.5569 - accuracy: 1.0000 - val_loss: 21.6282 - val_accuracy: 0.6500\n",
            "Epoch 98/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 20.4147 - accuracy: 1.0000 - val_loss: 21.4922 - val_accuracy: 0.6500\n",
            "Epoch 99/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 20.2847 - accuracy: 0.9880 - val_loss: 21.3639 - val_accuracy: 0.6500\n",
            "Epoch 100/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 20.1411 - accuracy: 1.0000 - val_loss: 21.2211 - val_accuracy: 0.6000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 21.2211 - accuracy: 0.6000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Inference**"
      ],
      "metadata": {
        "id": "A3nfrdIPmTQo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import load_model\n",
        "import numpy as np\n",
        "\n",
        "# Load the model\n",
        "model = load_model('/content/outputimages/best_model_fold_1.h5')\n",
        "\n",
        "# Load and preprocess an image\n",
        "def load_and_preprocess_image(img_path):\n",
        "    img = image.load_img(img_path, target_size=(64, 64))\n",
        "    img_tensor = image.img_to_array(img)\n",
        "    img_tensor = np.expand_dims(img_tensor, axis=0)\n",
        "    img_tensor /= 255.0\n",
        "    return img_tensor\n",
        "\n",
        "img_path = '/content/outputimages/ankan/1_0_5373.jpg'  # Replace with your image path\n",
        "img_tensor = load_and_preprocess_image(img_path)\n",
        "\n",
        "img2_path = '/content/outputimages/dks/1_0_5989.jpg'\n",
        "img2_tensor = load_and_preprocess_image(img2_path)\n",
        "\n",
        "# Predict the class\n",
        "predictions = model.predict(img_tensor)\n",
        "predicted_class = np.argmax(predictions[0])\n",
        "print(f\"Predicted class: {predicted_class}\")\n",
        "\n",
        "predictions2 = model.predict(img2_tensor)\n",
        "predicted_class2 = np.argmax(predictions2[0])\n",
        "print(f\"Predicted class: {predicted_class2}\")\n",
        "\n",
        "# Optionally, get class labels from train generator\n",
        "label_map = (train_generator.class_indices)\n",
        "label_map = dict((v, k) for k, v in label_map.items())  # Swapping keys and values\n",
        "predicted_label = label_map[predicted_class]\n",
        "print(f\"Predicted label: {predicted_label}\")\n",
        "\n",
        "predicted_label2 = label_map[predicted_class2]\n",
        "print(f\"Predicted label: {predicted_label2}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-EUEop1RUwRK",
        "outputId": "2783401e-1946-4a85-e0c0-7c9728430455"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 101ms/step\n",
            "Predicted class: 2\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Predicted class: 4\n",
            "Predicted label: ankan\n",
            "Predicted label: dks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Correct Predictions - Boom (Avishek Bhattacharjee)"
      ],
      "metadata": {
        "id": "wo-7HKaamYyG"
      }
    }
  ]
}